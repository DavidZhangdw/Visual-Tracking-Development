# Transformer Tracking

This repository is a paper digest of Transformer-related approaches in vision tracking tasks. Currently, tasks in this repository include **Single Object Tracking (SOT)**, **Video Object Segmentation (VOS)**, **Multiple Object Tracking (MOT)**, **Video Instance Segmentation (VIS)**, **Video Object Detection (VOD)**, **3D Object Tracking (3DOT)** and **Object Re-Identification (ReID)**. Note that some trackers involving a non-local attention mechanism are also collected. Papers are listed in alphabetical order of the first character.



## :bookmark:Single Object Tracking (SOT)

### CVPR 2020:tada::tada::tada:

- **SiamAttn** (Deformable Siamese Attention Networks for Visual Object Tracking) [[link](https://arxiv.org/abs/2004.06711)]

### ICPR 2020

- **VTT** (VTT: Long-term Visual Tracking with Transformers) [[link](https://pure.qub.ac.uk/en/publications/vtt-long-term-visual-tracking-with-transformers)]

### CVPR 2021:tada::tada::tada:

- **SiamGAT** (Graph Attention Tracking) [[link](https://arxiv.org/abs/2011.11204)]
- **STMTrack** (STMTrack: Template-free Visual Tracking with Space-time Memory Networks) [[link](https://arxiv.org/abs/2104.00324)]
- **TMT** (Transformer Meets Tracker: Exploiting Temporal Context for Robust Visual Tracking) [[link](https://arxiv.org/abs/2103.11681)]
- **TransT** (Transformer Tracking) [[link](https://arxiv.org/abs/2103.15436)]

### ICCV 2021:tada::tada::tada:

- **AutoMatch** (Learn to Match: Automatic Matching Network Design for Visual Tracking) [[link](https://arxiv.org/abs/2108.00803)]
- **DTT** (High-Performance Discriminative Tracking With Transformers) [[link](https://openaccess.thecvf.com/content/ICCV2021/html/Yu_High-Performance_Discriminative_Tracking_With_Transformers_ICCV_2021_paper.html)]
- **DualTFR** (Learning Tracking Representations via Dual-Branch Fully Transformer Networks) [[link](https://arxiv.org/abs/2112.02571)]
- **HiFT** (HiFT: Hierarchical Feature Transformer for Aerial Tracking) [[link](https://arxiv.org/abs/2108.00202)]
- **SAMN** (Learning Spatio-Appearance Memory Network for High-Performance Visual Tracking) [[link](https://arxiv.org/abs/2009.09669)]
- **STARK** (Learning Spatio-Temporal Transformer for Visual Tracking) [[link](https://arxiv.org/abs/2103.17154)]

### Preprint 2021

- **E.T.Track** (Efficient Visual Tracking with Exemplar Transformers) [[link](https://arxiv.org/abs/2112.09686)]
- **MFGNet** (MFGNet: Dynamic Modality-Aware Filter Generation for RGB-T Tracking) [[link](https://arxiv.org/abs/2107.10433)]
- **SwinTrack** (SwinTrack: A Simple and Strong Baseline for Transformer Tracking) [[link](https://arxiv.org/abs/2112.00995)]
- **TREG** (Target Transformed Regression for Accurate Tracking) [[link](https://arxiv.org/abs/2104.00403)]
- **TrTr** (TrTr: Visual Tracking with Transformer) [[link](https://arxiv.org/abs/2105.03817)]

### CVPR 2022:tada::tada::tada:

- **CSWinTT** (Transformer Tracking with Cyclic Shifting Window Attention) [[link](https://arxiv.org/abs/2205.03806)]
- **GTELT** (Global Tracking via Ensemble of Local Trackers) [[link](https://arxiv.org/abs/2203.16092)]
- **MixFormer** (MixFormer: End-to-End Tracking with Iterative Mixed Attention) [[link](https://arxiv.org/abs/2203.11082)]
- **RBO** (Ranking-Based Siamese Visual Tracking) [[link](https://arxiv.org/abs/2205.11761)]
- **SBT** (Correlation-Aware Deep Tracking) [[link](https://arxiv.org/abs/2203.01666)]
- **STNet** (Spiking Transformers for Event-based Single Object Tracking) [[link](https://openaccess.thecvf.com/content/CVPR2022/html/Zhang_Spiking_Transformers_for_Event-Based_Single_Object_Tracking_CVPR_2022_paper.html)]
- **TCTrack** (TCTrack: Temporal Contexts for Aerial Tracking) [[link](https://arxiv.org/abs/2203.01885)]
- **ToMP** (Transforming Model Prediction for Tracking) [[link](https://arxiv.org/abs/2203.11192)]
- **UDAT** (Unsupervised Domain Adaptation for Nighttime Aerial Tracking) [[link](https://arxiv.org/abs/2203.10541)]
- **UTT** (Unified Transformer Tracker for Object Tracking) [[link](https://arxiv.org/abs/2203.15175)]

### ECCV 2022:tada::tada::tada:

- **AiATrack** (AiATrack: Attention in Attention for Transformer Visual Tracking) [[link](https://arxiv.org/abs/2207.09603)]
- **OSTrack** (Joint Feature Learning and Relation Modeling for Tracking: A One-Stream Framework) [[link](https://arxiv.org/abs/2203.11991)]
- **Unicorn** (Towards Grand Unification of Object Tracking) [[link](https://arxiv.org/abs/2207.07078)]

### AAAI 2022

- **APFNet** (Attribute-based Progressive Fusion Network for RGBT Tracking) [[link](https://aaai-2022.virtualchair.net/poster_aaai7747)]

### IJCAI 2022

- **InBN** (Learning Target-aware Representation for Visual Tracking via Informative Interactions) [[link](https://arxiv.org/abs/2201.02526)]
- **SparseTT** (SparseTT: Visual Tracking with Sparse Transformers) [[link](https://arxiv.org/abs/2205.03776)]

### MICCAI 2022

- **TLT** (Transformer Lesion Tracker) [[link](https://arxiv.org/abs/2206.06252)]

### WACV 2022

- **SiamTPN** (Siamese Transformer Pyramid Networks for Real-Time UAV Tracking) [[link](https://arxiv.org/abs/2110.08822)]

### Preprint 2022

- **HCAT** (Efficient Visual Tracking via Hierarchical Cross-Attention Transformer) [[link](https://arxiv.org/abs/2203.13537)]
- **SiamLA** (Learning Localization-aware Target Confidence for Siamese Visual Tracking) [[link](https://arxiv.org/abs/2204.14093)]
- **SimTrack** (Backbone is All Your Need: A Simplified Architecture for Visual Object Tracking) [[link](https://arxiv.org/abs/2203.05328)]
- **TransT-M** (High-Performance Transformer Tracking) [[link](https://arxiv.org/abs/2203.13533)]



## :bookmark:Video Object Segmentation (VOS)

### ICCV 2019:tada::tada::tada:

- **STM** (Video Object Segmentation using Space-Time Memory Networks) [[link](https://arxiv.org/abs/1904.00607)]

### CVPR 2020:tada::tada::tada:

- **MAST** (MAST: A Memory-Augmented Self-supervised Tracker) [[link](https://arxiv.org/abs/2002.07793)]
- **TVOS** (A Transductive Approach for Video Object Segmentation) [[link](https://arxiv.org/abs/2004.07193)]

### NeurIPS 2020:tada::tada::tada:

- **AFB-URR** (Video Object Segmentation with Adaptive Feature Bank and Uncertain-Region Refinement) [[link](https://arxiv.org/abs/2010.07958)]

### ECCV 2020:tada::tada::tada:

- **GCM** (Fast Video Object Segmentation using the Global Context Module) [[link](https://arxiv.org/abs/2001.11243)]
- **GraphMemVOS** (Video Object Segmentation with Episodic Graph Memory Networks) [[link](https://arxiv.org/abs/2007.07020)]
- **KMN** (Kernelized Memory Network for Video Object Segmentation) [[link](https://arxiv.org/abs/2007.08270)]

### CVPR 2021:tada::tada::tada:

- **GIEL** (Video Object Segmentation Using Global and Instance Embedding Learning) [[link](https://openaccess.thecvf.com/content/CVPR2021/html/Ge_Video_Object_Segmentation_Using_Global_and_Instance_Embedding_Learning_CVPR_2021_paper.html)]
- **LCM** (Learning Position and Target Consistency for Memory-based Video Object Segmentation) [[link](https://arxiv.org/abs/2104.04329)]
- **RMNet** (Efficient Regional Memory Network for Video Object Segmentation) [[link](https://arxiv.org/abs/2103.12934)]
- **SSTVOS** (SSTVOS: Sparse Spatiotemporal Transformers for Video Object Segmentation) [[link](https://arxiv.org/abs/2101.08833)]
- **SwiftNet** (SwiftNet: Real-time Video Object Segmentation) [[link](https://arxiv.org/abs/2102.04604)]

### NeurIPS 2021:tada::tada::tada:

- **AOT** (Associating Objects with Transformers for Video Object Segmentation) [[link](https://arxiv.org/abs/2106.02638)]
- **STCN** (Rethinking Space-Time Networks with Improved Memory Coverage for Efficient Video Object Segmentation) [[link](https://arxiv.org/abs/2106.05210)]

### ICCV 2021:tada::tada::tada:

- **DINO** (Emerging Properties in Self-Supervised Vision Transformers) [[link](https://arxiv.org/abs/2104.14294)]
- **HMMN** (Hierarchical Memory Matching Network for Video Object Segmentation) [[link](https://arxiv.org/abs/2109.11404)]
- **JOINT** (Joint Inductive and Transductive Learning for Video Object Segmentation) [[link](https://arxiv.org/abs/2108.03679)]
- **MotionGroup** (Self-supervised Video Object Segmentation by Motion Grouping) [[link](https://arxiv.org/abs/2104.07658)]
- **SAMN** (Learning Spatio-Appearance Memory Network for High-Performance Visual Tracking) [[link](https://arxiv.org/abs/2009.09669)]

### AAAI 2021

- **STG-Net** (Spatiotemporal Graph Neural Network based Mask Reconstruction for Video Object Segmentation) [[link](https://arxiv.org/abs/2012.05499)]

### Preprint 2021

- **TransVOS** (TransVOS: Video Object Segmentation with Transformers) [[link](https://arxiv.org/abs/2106.00588)]

### CVPR 2022:tada::tada::tada:

- **LBDT** (Language-Bridged Spatial-Temporal Interaction for Referring Video Object Segmentation) [[link](https://arxiv.org/abs/2206.03789)]
- **MTTR** (End-to-End Referring Video Object Segmentation with Multimodal Transformers) [[link](https://arxiv.org/abs/2111.14821)]
- **RDE-VOS** (Recurrent Dynamic Embedding for Video Object Segmentation) [[link](https://arxiv.org/abs/2205.03761)]
- **ReferFormer** (Language as Queries for Referring Video Object Segmentation) [[link](https://arxiv.org/abs/2201.00487)]

### ECCV 2022:tada::tada::tada:

- **QDMN** (Learning Quality-aware Dynamic Memory for Video Object Segmentation) [[link](https://arxiv.org/abs/2207.07922)]
- **Unicorn** (Towards Grand Unification of Object Tracking) [[link](https://arxiv.org/abs/2207.07078)]
- **XMem** (XMem: Long-Term Video Object Segmentation with an Atkinson-Shiffrin Memory Model) [[link](https://arxiv.org/abs/2207.07115)]

### AAAI 2022

- **SITVOS** (Siamese Network with Interactive Transformer for Video Object Segmentation) [[link](https://arxiv.org/abs/2112.13983)]

### WACV 2022

- **BMVOS** (Pixel-Level Bijective Matching for Video Object Segmentation) [[link](https://arxiv.org/abs/2110.01644)]

### Preprint 2022

- **AOST** (Associating Objects with Scalable Transformers for Video Object Segmentation) [[link](https://arxiv.org/abs/2203.11442)]
- **INO** (In-N-Out Generative Learning for Dense Unsupervised Video Segmentation) [[link](https://arxiv.org/abs/2203.15312)]
- **Locater** (Local-Global Context Aware Transformer for Language-Guided Video Segmentation) [[link](https://arxiv.org/abs/2203.09773)]
- **VLGM+LMDF** (Deeply Interleaved Two-Stream Encoder for Referring Video Segmentation) [[link](https://arxiv.org/abs/2203.15969)]



## :bookmark:Multiple Object Tracking (MOT)

### CVPR 2021:tada::tada::tada:

- **MeNToS** (MeNToS: Tracklets Association with a Space-Time Memory Network) [[link](https://arxiv.org/abs/2107.07067)]

### Preprint 2021

- **MeNToS** (Multi-Object Tracking and Segmentation with a Space-Time Memory Network) [[link](https://arxiv.org/abs/2110.11284)]
- **MO3TR** (Looking Beyond Two Frames: End-to-End Multi-Object Tracking Using Spatial and Temporal Transformers) [[link](https://arxiv.org/abs/2103.14829)]
- **RelationTrack** (RelationTrack: Relation-aware Multiple Object Tracking with Decoupled Representation) [[link](https://arxiv.org/abs/2105.04322)]
- **TransCenter** (TransCenter: Transformers with Dense Queries for Multiple-Object Tracking) [[link](https://arxiv.org/abs/2103.15145)]
- **TransMOT** (TransMOT: Spatial-Temporal Graph Transformer for Multiple Object Tracking) [[link](https://arxiv.org/abs/2104.00194)]
- **TransTrack** (TransTrack: Multiple Object Tracking with Transformer) [[link](https://arxiv.org/abs/2012.15460)]

### CVPR 2022:tada::tada::tada:

- **GTR** (Global Tracking Transformers) [[link](https://arxiv.org/abs/2203.13250)]
- **MeMOT** (MeMOT: Multi-Object Tracking with Memory) [[link](https://arxiv.org/abs/2203.16761)]
- **Time3D** (Time3D: End-to-End Joint Monocular 3D Object Detection and Tracking for Autonomous Driving) [[link](https://arxiv.org/abs/2205.14882)]
- **TrackFormer** (TrackFormer: Multi-Object Tracking with Transformers) [[link](https://arxiv.org/abs/2101.02702)]
- **TRL** (Exploiting Temporal Relations on Radar Perception for Autonomous Driving) [[link](https://arxiv.org/abs/2204.01184)]
- **UTT** (Unified Transformer Tracker for Object Tracking) [[link](https://arxiv.org/abs/2203.15175)]

### ECCV 2022:tada::tada::tada:

- **MOTR** (MOTR: End-to-End Multiple-Object Tracking with TRansformer) [[link](https://arxiv.org/abs/2105.03247)]
- **P3AFormer** (Tracking Objects as Pixel-wise Distributions) [[link](https://arxiv.org/abs/2207.05518)]
- **Unicorn** (Towards Grand Unification of Object Tracking) [[link](https://arxiv.org/abs/2207.07078)]

### Preprint 2022

- **PatchTrack** (PatchTrack: Multiple Object Tracking Using Frame Patches) [[link](https://arxiv.org/abs/2201.00080)]



## :bookmark:Video Instance Segmentation (VIS)

### CVPR 2021:tada::tada::tada:

- **VisTR** (End-to-End Video Instance Segmentation with Transformers) [[link](https://arxiv.org/abs/2011.14503)]

### NeurIPS 2021:tada::tada::tada:

- **IFC** (Video Instance Segmentation using Inter-Frame Communication Transformers) [[link](https://arxiv.org/abs/2106.03299)]

### IROS 2021

- **LMANet** (Local Memory Attention for Fast Video Semantic Segmentation) [[link](https://arxiv.org/abs/2101.01715)]

### ICIP 2021

- **TMANet** (Temporal Memory Attention for Video Semantic Segmentation) [[link](https://arxiv.org/abs/2102.08643)]

### Preprint 2021

- **Mask2Former** (Mask2Former for Video Instance Segmentation) [[link](https://arxiv.org/abs/2112.10764)]
- **QueryTrack** (Tracking Instances as Queries) [[link](https://arxiv.org/abs/2106.11963)]

### CVPR 2022:tada::tada::tada:

- **EfficientVIS** (Efficient Video Instance Segmentation via Tracklet Query and Proposal) [[link](https://arxiv.org/abs/2203.01853)]
- **TeViT** (Temporally Efficient Vision Transformer for Video Instance Segmentation) [[link](https://arxiv.org/abs/2204.08412)]
- **Video K-Net** (Video K-Net: A Simple, Strong, and Unified Baseline for Video Segmentation) [[link](https://arxiv.org/abs/2204.04656)]

### ECCV 2022:tada::tada::tada:

- **Seqformer** (SeqFormer: a Frustratingly Simple Model for Video Instance Segmentation) [[link](https://arxiv.org/abs/2112.08275)]

### AAAI 2022

- **HITF** (Hybrid Instance-aware Temporal Fusion for Online Video Instance Segmentation) [[link](https://arxiv.org/abs/2112.01695)]

### ICASSP 2022

- **DefVIS** (Deformable VisTR: Spatio temporal deformable attention for video instance segmentation) [[link](https://arxiv.org/abs/2203.06318)]

### WACV 2022

- **VPS-Transformer** (Time-Space Transformers for Video Panoptic Segmentation) [[link](https://openaccess.thecvf.com/content/WACV2022/html/Petrovai_Time-Space_Transformers_for_Video_Panoptic_Segmentation_WACV_2022_paper.html)]

### Preprint 2022

- **MS-STS VIS** (Video Instance Segmentation via Multi-scale Spatio-temporal Split Attention Transformer) [[link](https://arxiv.org/abs/2203.13253)]
- **VITA** (VITA: Video Instance Segmentation via Object Token Association) [[link](https://arxiv.org/abs/2206.04403)]



## :bookmark:Video Object Detection (VOD)

### Preprint 2020

- **TCTR** (Temporal-Channel Transformer for 3D Lidar-Based Video Object Detection in Autonomous Driving) [[link](https://arxiv.org/abs/2011.13628)]

### Preprint 2021

- **TransVOD** (End-to-End Video Object Detection with Spatial-Temporal Transformers) [[link](https://arxiv.org/abs/2105.10920)]

### CVPR 2022:tada::tada::tada:

- **SLT-Net** (Implicit Motion Handling for Video Camouflaged Object Detection) [[link](https://arxiv.org/abs/2203.07363)]

### Preprint 2022

- **TransVOD++** (TransVOD: End-to-end Video Object Detection with Spatial-Temporal Transformers) [[link](https://arxiv.org/abs/2201.05047)]
- **UFO** (A Unified Transformer Framework for Group-based Segmentation: Co-Segmentation, Co-Saliency Detection and Video Salient Object Detection) [[link](https://arxiv.org/abs/2203.04708)]



## :bookmark:3D Object Tracking (3DOT)

### IROS 2021

- **PTT** (PTT: Point-Track-Transformer Module for 3D Single Object Tracking in Point Clouds) [[link](https://arxiv.org/abs/2108.06455)]

### BMVC 2021

- **LTTR** (3D Object Tracking with Transformer) [[link](https://arxiv.org/abs/2110.14921)]

### CVPR 2022:tada::tada::tada:

- **PTTR** (PTTR: Relational 3D Point Cloud Object Tracking with Transformer) [[link](https://arxiv.org/abs/2112.02857)]
- **TransFusion** (TransFusion: Robust LiDAR-Camera Fusion for 3D Object Detection with Transformers) [[link](https://arxiv.org/abs/2203.11496)]

### ECCV 2022:tada::tada::tada:

- **CMT** (CMT: Context-Matching-Guided Transformer for 3D Tracking in Point Clouds) [[link](https://github.com/jasongzy/CMT)]



## :bookmark:Object Re-Identification (ReID)

### CVPR 2021:tada::tada::tada:

- **PAT** (Diverse Part Discovery: Occluded Person Re-identification with Part-Aware Transformer) [[paper](https://arxiv.org/abs/2106.04095)]

### ICCV 2021:tada::tada::tada:

- **APD** (Transformer Meets Part Model: Adaptive Part Division for Person Re-Identification) [[paper](https://openaccess.thecvf.com/content/ICCV2021W/HTCV/html/Lai_Transformer_Meets_Part_Model_Adaptive_Part_Division_for_Person_Re-Identification_ICCVW_2021_paper.html)]
- **TransReID** (TransReID: Transformer-based Object Re-Identification) [[paper](https://arxiv.org/abs/2102.04378)]

### MM 2021

- **HAT** (HAT: Hierarchical Aggregation Transformers for Person Re-identification) [[paper](https://arxiv.org/abs/2107.05946)]

### Preprint 2021

- **AAformer** (AAformer: Auto-Aligned Transformer for Person Re-Identification) [[paper](https://arxiv.org/abs/2104.00921)]
- **CMTR** (CMTR: Cross-modality Transformer for Visible-infrared Person Re-identification) [[paper](https://arxiv.org/abs/2110.08994)]
- **STT** (Spatiotemporal Transformer for Video-based Person Re-identification) [[paper](https://arxiv.org/abs/2103.16469)]
- **TMT** (A Video Is Worth Three Views: Trigeminal Transformers for Video-based Person Re-identification) [[paper](https://arxiv.org/abs/2104.01745)]
