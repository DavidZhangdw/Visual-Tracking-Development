# Visual-Tracking-Development
![recent_develop](https://github.com/DavidZhangdw/Visual-Tracking-Development/blob/master/img/Trackers%20.png?raw=true)

## Papers

### :star2: Recommendations :star2:

- **VOTSurvey:** Sajid Javed, Martin Danelljan, Fahad Shahbaz Khan, Muhammad Haris Khan, Michael Felsberg, Jiri Matas.<br />
  "Visual Object Tracking with Discriminative Filters and Siamese Networks: A Survey and Outlook." TAPMI (2023).
  [[paper](https://arxiv.org/abs/2112.02838)] 
  
- **DL4VT:** Seyed Mojtaba Marvasti-Zadeh, Li Cheng, Senior Member, Hossein Ghanei-Yakhdan, Shohreh Kasaei, Senior Member.<br />
  "Deep Learning for Visual Tracking: A Comprehensive Survey." ArXiv (2021).
  [[paper](https://arxiv.org/pdf/1912.00535.pdf)] 
  [[code](https://github.com/MMarvasti/Deep-Learning-for-Visual-Tracking-Survey)]
   
- **GIT:** Shiyu Hu, Xin Zhao, Lianghua Huang, Kaiqi Huang.<br />
  "Global Instance Tracking: Locating Target More Like Humans." IEEE TPAMI (2022).
  [[paper](https://arxiv.org/pdf/2202.13073.pdf)] 
  [[code](http://videocube.aitestunion.com/)]
      
- **SAM:** Alexander Kirillov, Eric Mintun, Nikhila Ravi, Hanzi Mao, Chloe Rolland, Laura Gustafson, Tete Xiao, Spencer Whitehead, Alexander C. Berg, Wan-Yen Lo, Piotr Dollár, Ross Girshick.<br />
  "Segment Anything." ArXiv (2023).
  [[paper](https://arxiv.org/pdf/2304.02643v1.pdf)] 
  [[homepage](https://segment-anything.com/)] 
  [[code](https://github.com/facebookresearch/segment-anything)]
  
- **TAM:** Jinyu Yang, Mingqi Gao, Zhe Li, Shang Gao, Fangjing Wang, Feng Zheng.<br />
  "Track Anything: Segment Anything Meets Videos." ArXiv (2023).
  [[paper](https://arxiv.org/abs/2304.11968)] 
  [[code](https://github.com/gaomingqi/Track-Anything)]
  
- **SAM-Track:** Yangming Cheng, Liulei Li, Yuanyou Xu, Xiaodi Li, Zongxin Yang, Wenguan Wang, Yi Yang.<br />
  "Segment-and-Track Anything." ArXiv (2023).
  [[paper](https://arxiv.org/abs/2305.06558)] 
  [[code](https://github.com/z-x-yang/Segment-and-Track-Anything)]
  
- **SEEM:** Xueyan Zou, Jianwei Yang, Hao Zhang, Feng Li, Linjie Li, Jianfeng Gao, Yong Jae Lee.<br />
  "Segment Everything Everywhere All at Once." ArXiv (2023).
  [[paper](https://arxiv.org/pdf/2304.06718v1.pdf)] 
  [[code](https://github.com/UX-Decoder/Segment-Everything-Everywhere-All-At-Once)]

- **SAM-PT:** Frano Rajič, Lei Ke, Yu-Wing Tai, Chi-Keung Tang, Martin Danelljan, Fisher Yu.<br />
  "Segment Anything Meets Point Tracking." ArXiv (2023).
  [[paper](https://arxiv.org/abs/2307.01197)] 
  [[code](https:/github.com/syscv/sam-pt)]
  
- **ReviewLLM:** Jiaqi Wang, Zhengliang Liu, Lin Zhao, Zihao Wu, Chong Ma, Sigang Yu, Haixing Dai.<br />
  "Review of Large Vision Models and Visual Prompt Engineering." ArXiv (2023).
  [[paper](https://arxiv.org/abs/2307.00855)]
  [[code](https://github.com/xxx)]

- **Omnimotion:** Qianqian Wang, Yen-Yu Chang, Ruojin Cai, Zhengqi Li, Bharath Hariharan, Aleksander Holynski, Noah Snavely.<br />
  "Tracking Everything Everywhere All at Once." ArXiv (2023).
  [[paper](https://arxiv.org/abs/2306.05422)] 
  [[code](https://omnimotion.github.io/)]
  
- **ChatVideo:** Junke Wang, Dongdong Chen, Chong Luo, Xiyang Dai, Lu Yuan, Zuxuan Wu, Yu-Gang Jiang.<br />
  "ChatVideo: A Tracklet-centric Multimodal and Versatile Video Understanding System." ArXiv (2023).
  [[paper](https://arxiv.org/abs/2304.14407)] 
  [[code](https://www.wangjunke.info/ChatVideo/)]
  
- **Video-ChatGPT:** Muhammad Maaz, Hanoona Rasheed, Salman Khan, Fahad Shahbaz Khan.<br />
  "Video-ChatGPT: Towards Detailed Video Understanding via Large Vision and Language Models." ArXiv (2023).
  [[paper](https://arxiv.org/abs/2306.05424)] 
  [[code](https://github.com/mbzuai-oryx/Video-ChatGPT)]
  
- **SegGPT:** Xinlong Wang, Xiaosong Zhang, Yue Cao, Wen Wang, Chunhua Shen, Tiejun Huang.<br />
  "SegGPT: Segmenting Everything In Context." ArXiv (2023).
  [[paper](https://arxiv.org/abs/2304.03284)] 
  [[code](https://github.com/baaivision/Painter)]
  
- **MixFormerV2:** Yutao Cui, Tianhui Song, Gangshan Wu, Limin Wang.<br />
  "MixFormerV2: Efficient Fully Transformer Tracking." ArXiv (2023).
  [[paper](https://arxiv.org/abs/2305.15896)] 
  [[code](https://github.com/MCG-NJU/MixFormerV2)]
  
- **CO-MOT:** Feng Yan, Weixin Luo, Yujie Zhong, Yiyang Gan, Lin Ma.<br />
  "CO-MOT: Bridging the Gap Between End-to-end and Non-End-to-end Multi-Object Tracking." ArXiv (2023).
  [[paper](https://arxiv.org/abs/2305.12724)] 
  [[code](https://github.com/BingfengYan/CO-MOT)]
      
### CVPR 2023

- **X-Decoder:** Xueyan Zou, Zi-Yi Dou, Jianwei Yang, Zhe Gan, Linjie Li, Chunyuan Li, Xiyang Dai, Harkirat Behl, Jianfeng Wang, Lu Yuan, Nanyun Peng, Lijuan Wang, Yong Jae Lee, Jianfeng Gao.<br />
  "Generalized Decoding for Pixel, Image, and Language." CVPR (2023).
  [[paper](https://arxiv.org/abs/2212.11270)] 
  [[code](https://x-decoder-vl.github.io/)]
  
- **UNINEXT:** Bin Yan, Yi Jiang, Jiannan Wu, Dong Wang, Ping Luo, Zuhuan Yuan, Huchuan Lu.<br />
  "Universial Instance Perception as Object Discovery and Retrieval." CVPR (2023).
  [[paper](https://arxiv.org/abs/2303.06674)] 
  [[code](https://github.com/MasterBin-IIAU/UNINEXT)]
  
- **OmniTracker:** Junke Wang, Dongdong Chen, Zuxuan Wu, Chong Luo, Xiyang Dai, Lu Yuan, Yu-Gang Jiang.<br />
  "OmniTracker: Unifying Object Tracking by Tracking-with-Detection." CVPR (2023).
  [[paper](https://arxiv.org/abs/2303.12079)] 
  [[code](https://github.com/)]
  
- **DropMAE:** Qiangqiang Wu, Tianyu Yang, Ziquan Liu, Baoyuan Wu, Ying Shan, Antoni B. Chan.<br />
  "DropMAE: Masked Autoencoders with Spatial-Attention Dropout for Tracking Tasks." CVPR (2023).
  [[paper](https://arxiv.org/abs/2304.00571)] 
  [[code](https://github.com/jimmy-dq/DropMAE)]
  
- **VideoTrack:** Fei Xie, Lei Chu, Jiahao Li, Yan Lu, Chao Ma.<br />
  "VideoTrack: Learning to Track Objects via Video Transformer." CVPR (2023).
  [[paper](https://arxiv.org/abs/x)] 
  [[code](https://github.com/phiphiphi31/VideoTrack)]
  
- **SwinV2:** Zhenda Xie, Zigang Geng, Jingcheng Hu, Zheng Zhang, Han Hu, Yue Cao.<br />
  "Revealing the Dark Secrets of Masked Image Modeling." CVPR (2023).
  [[paper](https://arxiv.org/abs/2205.13543)] 
  [[code](https://github.com/SwinTransformer/MIM-Depth-Estimation)]
  
- **ViPT:** Jiawen Zhu, Simiao Lai, Xin Chen, Dong Wang, Huchuan Lu.<br />
  "Visual Prompt Multi-Modal Tracking." CVPR (2023).
  [[paper](https://arxiv.org/abs/2303.10826)] 
  [[code](https://github.com/jiawen-zhu/ViPT)]
  
 - **JointNLT:** Li Zhou, Zikun Zhou, Kaige Mao, Zhenyu He.<br />
  "Joint Visual Grounding and Tracking with Natural Language Specification." CVPR (2023).
  [[paper](https://arxiv.org/abs/2303.12027)] 
  [[code](https://github.com/lizhou-cs/JointNLT)]
  
 - **ARKitTrack:** Haojie Zhao, Junsong Chen, Lijun Wang, Huchuan Lu.<br />
  "ARKitTrack: A New Diverse Dataset for Tracking Using Mobile RGB-D Data." CVPR (2023).
  [[paper](https://arxiv.org/abs/2303.13885)] 
  [[code](https://arkittrack.github.io/)]
  
 - **GRM:** Shenyuan Gao, Chunluan Zhou, Jun Zhang.<br />
  "Generalized Relation Modeling for Transformer Tracking." CVPR (2023).
  [[paper](https://arxiv.org/pdf/2303.16580v1.pdf)] 
  [[code](https://github.com/Little-Podi/GRM)]
  
 - **ARTrack:** Xing Wei, Yifan Bai, Yongchao Zheng, Dahu Shi, Yihong Gong.<br />
  "Autoregressive Visual Tracking." CVPR (2023).
  [[paper](https://openaccess.thecvf.com/content/CVPR2023/html/Wei_Autoregressive_Visual_Tracking_CVPR_2023_paper.html)] 
  [[code](https://github.com/MIV-XJTU/ARTrack)]
  
 - **MAT:** Haojie Zhao, Dong Wang, Huchuan Lu.<br />
  "Representation Learning for Visual Object Tracking by Masked Appearance Transfer." CVPR (2023).
  [[paper](https://openaccess.thecvf.com/content/CVPR2023/html/Zhao_Representation_Learning_for_Visual_Object_Tracking_by_Masked_Appearance_Transfer_CVPR_2023_paper.html)] 
  [[code](https://github.com/difhnp/MAT)]
  
 - **EMT:** Jinyu Yang, Shang Gao, Zhe Li, Feng Zheng, Aleš Leonardis.<br />
  "Resource-Efficient RGBD Aerial Tracking." CVPR (2023).
  [[paper](https://openaccess.thecvf.com/content/CVPR2023/html/Yang_Resource-Efficient_RGBD_Aerial_Tracking_CVPR_2023_paper.html)] 
  [[code](https://github.com/yjybuaa/RGBDAerialTracking)]
  
 - **TBSI:** Tianrui Hui, Zizheng Xun, Fengguang Peng, Junshi Huang, Xiaoming Wei, Xiaolin Wei, Jiao Dai, Jizhong Han, Si Liu.<br />
  "Bridging Search Region Interaction With Template for RGB-T Tracking." CVPR (2023).
  [[paper](https://openaccess.thecvf.com/content/CVPR2023/html/Hui_Bridging_Search_Region_Interaction_With_Template_for_RGB-T_Tracking_CVPR_2023_paper.html)] 
  [[code](https://github.com/RyanHTR/TBSI)]
  
 - **VisTracker:** Xianghui Xie, Bharat Lal Bhatnagar, Gerard Pons-Moll.<br />
  "Visibility Aware Human-Object Interaction Tracking from Single RGB Camera." CVPR (2023).
  [[paper](https://arxiv.org/abs/2303.16479v1)] 
  [[code](https://virtualhumans.mpi-inf.mpg.de/VisTracker/)]
  
 - **OVTrack:** Siyuan Li, Tobias Fischer, Lei Ke, Henghui Ding, Martin Danelljan, Fisher Yu.<br />
  "OVTrack: Open-Vocabulary Multiple Object Tracking." CVPR (2023).
  [[paper](https://arxiv.org/abs/2304.08408)] 
  [[code](https://www.vis.xyz/pub/ovtrack/)]
  
 - **SeqTrack:** Xin Chen, Houwen Peng, Dong Wang, Huchuan Lu, Han Hu.<br />
  "SeqTrack: Sequence to Sequence Learning for Visual Object Tracking." CVPR (2023).
  [[paper](https://arxiv.org/abs/2304.14394)] 
  [[code](https://github.com/microsoft/VideoX)]
  
 - **ImageBind:** Rohit Girdhar, Alaaeldin El-Nouby, Zhuang Liu, Mannat Singh, Kalyan Vasudev Alwala, Armand Joulin, Ishan Misra.<br />
  "IMAGEBIND: One Embedding Space To Bind Them All." CVPR (2023).
  [[paper](https://arxiv.org/abs/2305.05665)] 
  [[code](https://github.com/facebookresearch/ImageBind)]
  
 - **TCOW:** Basile Van Hoorick, Pavel Tokmakov, Simon Stent, Jie Li, Carl Vondrick.<br />
  "Tracking through Containers and Occluders in the Wild." CVPR (2023).
  [[paper](https://arxiv.org/abs/2305.03052)] 
  [[code](https://tcow.cs.columbia.edu/)]
  
  
### IJCAI 2023

- **OSP2B:** Jiahao Nie, Zhiwei He, Yuxiang Yang, Zhengyi Bao, Mingyu Gao, Jing Zhang.<br />
  "OSP2B: One-Stage Point-to-Box Network for 3D Siamese Tracking." IJCAI (2023).
  [[paper](https://arxiv.org/abs/2304.11584)] 
  [[code](https://github.com/HaozheQi/P2B)]
  
  
### ICRA 2023

- **SGDViT:** Liangliang Yao, Changhong Fu, Sihang Li, Guangze Zheng, Junjie Ye.<br />
  "SGDViT: Saliency-Guided Dynamic Vision Transformer for UAV Tracking." ICRA (2023).
  [[paper](https://arxiv.org/abs/2303.04378v1)] 
  [[code](https://github.com/vision4robotics/SGDViT)]
  
- **ClimRT:** Changhong Fu, Mutian Cai, Sihang Li, Kunhan Lu, Haobo Zuo, Chongjun Liu.<br />
  "Continuity-Aware Latent Interframe Information Mining for Reliable UAV Tracking." ICRA (2023).
  [[paper](https://arxiv.org/abs/2303.04525v1)] 
  [[code](https://github.com/vision4robotics/ClimRT)]
  
### IROS 2023

- **CDT:** Kunhan Lu, Changhong Fu, Yucheng Wang, Haobo Zuo, Guangze Zheng, and Jia Pan.<br />
  "Cascaded Denoising Transformer for UAV Nighttime Tracking." RAL (2023).
  [[paper](https://arxiv.org/xxxx)] 
  [[code](https://github.com/vision4robotics/CDT)]
  
- **TRTrack:** Sihang Li, Changhong Fu.<br />
  "TRTrack: Boosting UAV Object Tracking with Voxel-based Trajectory-aware Reconstruction Training." IROS (2023).
  [[paper](https://arxiv.org/abs/xxxx)] 
  [[code](https://github.com/vision4robotics/TRTrack)]
  
### WACV 2023

- **E.T.Track:** Philippe Blatter, Menelaos Kanakis, Martin Danelljan, Luc Van Gool.<br />
  "Efficient Visual Tracking with Exemplar Transformers." WACV (2023).
  [[paper](https://arxiv.org/abs/2112.09686)] 
  [[code](https://github.com/pblatter/ettrack)]
  

### AAAI 2023

- **CTTrack:** Zikai Song, Run Luo, Junqing Yu, Yi-Ping Phoebe Chen, Wei Yang.<br />
  "Compact Transformer Tracker with Correlative Masked Modeling." AAAI (2023).
  [[paper](https://arxiv.org/abs/2301.10938)] 
  [[code](https://github.com/HUSTDML/CTTrack)]
  
- **TATrack:** Kaijie He, Canlong Zhang, Sheng Xie, Zhixin Li, Zhiwen Wang.<br />
  "Target-Aware Tracking with Long-term Context Attention." AAAI (2023).
  [[paper](https://arxiv.org/abs/2302.13840)] 
  [[code](https://github.com/hekaijie123/TATrack)]
  
- **GdaTFT:** Yun Liang; Qiaoqiao Li; Fumian Long.<br />
  "Global Dilated Attention and Target Focusing Network for Robust Tracking." AAAI (2023).
  [[paper](https://underline.io/lecture/69278-global-dilated-attention-and-target-focusing-network-for-robust-tracking)] 
  [[code](https://github.com/)]
  
- **GLT-T:** Jiahao Nie, Zhiwei He, Yuxiang Yang, Mingyu Gao, Jing Zhang.<br />
  "GLT-T: Global-Local Transformer Voting for 3D Single Object Tracking in Point Clouds." AAAI (2023).
  [[paper](https://arxiv.org/abs/2211.10927)] 
  [[extended](https://arxiv.org/abs/2304.00242)] 
  [[code](https://github.com/haooozi/GLT-T)]
  
- **RSPT:** Fangwei Zhong, Xiao Bi, Yudi Zhang, Wei Zhang, Yizhou Wang.<br />
  "RSPT: Reconstruct Surroundings and Predict Trajectories for Generalizable Active Object Tracking." AAAI (2023).
  [[paper](https://arxiv.org/abs/2304.03623)] 
  [[code](https://sites.google.com/view/aot-rspt)]
  
### NeurIPS 2022

- **SwinTrack:** Liting Lin, Heng Fan, Yong Xu, Haibin Ling.<br />
  "SwinTrack: A Simple and Strong Baseline for Transformer Tracking." NeurIPS (2022).
  [[paper](https://arxiv.org/abs/2112.00995)] 
  [[code](https://github.com/LitingLin/SwinTrack)]
  
- **VLTrack:** Mingzhe Guo, Zhipeng Zhang, Heng Fan, Liping Jing.<br />
  "Divert More Attention to Vision-Language Tracking." NeurIPS (2022).
  [[paper](https://arxiv.org/abs/2207.01076)] 
  [[code](https://github.com/JudasDie/SOTS)]
  
- **GKB:** Zhiyu Zhu, Junhui Hou, Xianqiang Lyu.<br />
  "Leaning Graph-embedded Key-event Back-tracing for Object Tracking in Event Clouds." NeurIPS (2022).
  [[paper](https://nips.cc/Conferences/2022/Schedule?showEvent=54651)] 
  [[code](https://github.com/xxxx)]
  
- **TAP-Vid:** Carl Doersch, Ankush Gupta, Larisa Markeeva, Lucas Smaira, Yusuf Aytar, Andrew Zisserman, Yi Yang.<br />
  "TAP-Vid: A Benchmark for Tracking Any Point in a Video." NeurIPS (2022).
  [[paper](https://arxiv.org/abs/2211.03726)] 
  [[code](https://github.com/deepmind/tapnet)]

  
### ECCV 2022

- **OSTrack:** Botao Ye, Hong Chang, Bingpeng Ma, Shiguang Shan.<br />
  "Joint Feature Learning and Relation Modeling for Tracking: A One-Stream Framework." ECCV (2022).
  [[paper](https://arxiv.org/abs/2203.11991)] 
  [[code](https://github.com/botaoye/OSTrack)]
  
- **Unicorn:** Bin Yan, Yi Jiang, Peize Sun, Dong Wang, Zehuan Yuan, Ping Luo, Huchuan Lu.<br />
  "Unicorn: Towards Grand Unification of Object Tracking." ECCV (2022) Oral.
  [[paper](https://arxiv.org/abs/2207.07078)] 
  [[code](https://github.com/MasterBin-IIAU/Unicorn)]
  
- **SimTrack:** Boyu Chen, Peixia Li, Lei Bai, Lei Qiao, Qiuhong Shen, Bo Li, Weihao Gan, Wei Wu, Wanli Ouyang.<br />
  "Backbone is All Your Need: A Simplified Architecture for Visual Object Tracking." ECCV (2022).
  [[paper](https://arxiv.org/abs/2203.05328)] 
  [[code](https://github.com/LPXTT/SimTrack)]
  
- **CIA:** Zhixiong Pi, Weitao Wan, Chong Sun, Changxin Gao, Nong Sang, Chen Li.<br />
  "Hierarchical Feature Embedding for Visual Tracking." ECCV (2022).
  [[paper](https://www.ecva.net/papers/eccv_2022/papers_ECCV/html/4400_ECCV_2022_paper.php)] 
  [[code](https://github.com/zxgravity/CIA)]
  
- **RTS:** Matthieu Paul,Martin Danelljan,Christoph Mayer,Luc Van Gool.<br />
  "Robust Visual Tracking by Segmentation." ECCV (2022).
  [[paper](https://arxiv.org/abs/2203.11191)] 
  [[code](https://github.com/visionml/pytracking)]
  
- **AiATrack:** Shenyuan Gao, Chunluan Zhou, Chao Ma, Xinggang Wang, Junsong Yuan.<br />
  "AiATrack: Attention in Attention for Transformer Visual Tracking." ECCV (2022).
  [[paper](https://arxiv.org/abs/2207.09603)] 
  [[code](https://github.com/Little-Podi/AiATrack)]

- **SLTtrack:** Minji Kim, Seungkwan Lee, Jungseul Ok, Bohyung Han, Minsu Cho.<br />
  "Towards Sequence-Level Training for Visual Tracking." ECCV (2022).
  [[paper](https://arxiv.org/abs/2208.05810)] 
  [[code](https://github.com/byminji/SLTtrack)]
  
- **FEAR:** Vasyl Borsuk, Roman Vei, Orest Kupyn, Tetiana Martyniuk, Igor Krashenyi, Jiři Matas.<br />
  "FEAR: Fast, Efficient, Accurate and Robust Visual Tracker." ECCV (2022).
  [[paper](https://arxiv.org/pdf/2112.07957.pdf)] 
  [[code](https://xxxxxxx)]
  
- **PersonPath22:** Bing Shuai, Alessandro Bergamo, Uta Buechler, Andrew Berneshawi, Alyssa Boden, Joseph Tighe.<br />
  "Large Scale Real-World Multi-Person Tracking." ECCV (2022).
  [[paper](https://arxiv.org/abs/2211.02175)] 
  [[code](https://amazon-science.github.io/tracking-dataset/personpath22.html)]
  
- **STNet:** Le Hui, Lingpeng Wang, Linghua Tang, Kaihao Lan, Jin Xie, Jian Yang.<br />
  "3D Siamese Transformer Network for Single Object Tracking on Point Clouds." ECCV (2022).
  [[paper](https://arxiv.org/abs/2207.11995)] 
  [[code](https://github.com/fpthink/STNet)]
  
- **P3AFormer:** Zelin Zhao, Ze Wu, Yueqing Zhuang, Boxun Li, Jiaya Jia.<br />
  "Tracking Objects as Pixel-wise Distributions." ECCV (2022).
  [[paper](https://arxiv.org/abs/2207.05518)] 
  [[code](https://sjtuytc.github.io/zelin_pages/p3aformer.html)]
  
- **TETer:** Siyuan Li, Martin Danelljan, Henghui Ding, Thomas E. Huang, Fisher Yu.<br />
  "Tracking Every Thing in the Wild." ECCV (2022).
  [[paper](https://arxiv.org/abs/2207.12978)] 
  [[code](http://vis.xyz/pub/tet)]
  
- **ByteTrack:** Yifu Zhang, Peize Sun, Yi Jiang, Dongdong Yu, Zehuan Yuan, Ping Luo, Wenyu Liu, Xinggang Wang.<br />
  "ByteTrack: Multi-Object Tracking by Associating Every Detection Box." ECCV (2022).
  [[paper](https://arxiv.org/pdf/2110.06864v2.pdf)] 
  [[code](https://github.com/ifzhang/ByteTrack)]

- **MOTR:** Fangao Zeng, Bin Dong, Yuang Zhang, Tiancai Wang, Xiangyu Zhang, Yichen Wei.<br />
  "MOTR: End-to-End Multiple-Object Tracking with Transformer." ECCV (2022).
  [[paper](https://arxiv.org/abs/2105.03247)] 
  [[code](https://github.com/megvii-research/MOTR)]
  
- **MTracker:** Yifu Zhang, Chunyu Wang, Xinggang Wang, Wenjun Zeng, Wenyu Liu.<br />
  "Robust Multi-Object Tracking by Marginal Inference." ECCV (2022).
  [[paper](https://arxiv.org/abs/2208.03727)] 
  [[code](https://xxxxxxx)]
  

  
  
### CVPR 2022

- **MixFormer:** Yutao Cui, Jiang Cheng, Limin Wang, Gangshan Wu.<br />
  "MixFormer: End-to-End Tracking with Iterative Mixed Attention." CVPR (2022).
  [[paper](https://arxiv.org/abs/2203.11082)] 
  [[code](https://github.com/MCG-NJU/MixFormer)]
  
- **OWTB:** Yang Liu, Idil Esen Zulfikar, Jonathon Luiten, Achal Dave, Deva Ramanan, Bastian Leibe, Aljoša Ošep, Laura Leal-Taixé.<br />
  "Opening up Open-World Tracking." CVPR (2022).
  [[paper](https://arxiv.org/abs/2104.11221)] 
  [[code](https://openworldtracking.github.io/)]
  
- **UTT:** Fan Ma, Mike Zheng Shou, Linchao Zhu, Haoqi Fan, Yilei Xu, Yi Yang, Zhicheng Yan.<br />
  "Unified Transformer Tracker for Object Tracking." CVPR (2022).
  [[paper](https://arxiv.org/abs/2203.15175)] 
  [[code](https://github.com/Flowerfan/Trackron)]
  
- **CSWinTT:** Zikai Song, Junqing Yu, Yi-Ping Phoebe Chen, Wei Yang.<br />
  "Transformer Tracking with Cyclic Shifting Window Attention." CVPR (2022).
  [[paper](https://arxiv.org/abs/2205.03806)] 
  [[code](https://github.com/SkyeSong38/CSWinTT)]
  
- **ToMP:** Christoph Mayer, Martin Danelljan, Goutam Bhat, Matthieu Paul, Danda Pani Paudel, Fisher Yu, Luc Van Gool.<br />
  "Transforming Model Prediction for Tracking." CVPR (2022).
  [[paper](https://arxiv.org/abs/2203.11192)] 
  [[code](https://github.com/visionml/pytracking)]
  
- **TCTrack:** Ziang Cao, Ziyuan Huang, Liang Pan, Shiwei Zhang, Ziwei Liu, Changhong Fu.<br />
  "TCTrack: Temporal Contexts for Aerial Tracking." CVPR (2022).
  [[paper](https://arxiv.org/abs/2203.01885)] 
  [[code](https://github.com/vision4robotics/TCTrack)]
  
- **SBT:** Fei Xie, Chunyu Wang, Guangting Wang, Yue Cao, Wankou Yang, Wenjun Zeng.<br />
  "Correlation-Aware Deep Tracking." CVPR (2022).
  [[paper](https://arxiv.org/abs/2203.01666)] 
  [[code](https://github.com/phiphiphi31/SuperSBT)]
  
- **AdaRS:** Yihao Li, Jun Yu, Zhongpeng Cai, Yuwen Pan.<br />
  "Cross-Modal Target Retrieval for Tracking by Natural Language." CVPR (2022).
  [[paper](https://openaccess.thecvf.com/content/CVPR2022W/ODRUM/html/Li_Cross-Modal_Target_Retrieval_for_Tracking_by_Natural_Language_CVPRW_2022_paper.html)] 
  [[code](xxxx)]
  
- **STNet:** Jiqing Zhang, Bo Dong, Haiwei Zhang, Jianchuan Ding, Felix Heide, Baocai Yin, Xin Yang.<br />
  "Spiking Transformers for Event-based Single Object Tracking." CVPR (2022).
  [[paper](https://openaccess.thecvf.com/content/CVPR2022/html/Zhang_Spiking_Transformers_for_Event-Based_Single_Object_Tracking_CVPR_2022_paper.html)] 
  [[code](https://github.com/Jee-King/CVPR2022_STNet)]
  
- **VTUAV:** Pengyu Zhang, Jie Zhao, Dong Wang, Huchuan Lu, Xiang Ruan.<br />
  "Visible-Thermal UAV Tracking: A Large-Scale Benchmark and New Baseline." CVPR (2022).
  [[paper](https://arxiv.org/abs/2204.04120)] 
  [[code](https://zhang-pengyu.github.io/DUT-VTUAV/)]
  
- **UAVMOT:** Shuai Liu, Xin Li, Huchuan Lu, You He.<br />
  "Multi-Object Tracking Meets Moving UAV." CVPR (2022).
  [[paper](https://arxiv.org/abs/xxxx.xxxx)] 
  [[code](https://github.com/LiuShuaiyr/UAVMOT)]
  
- **GTR:** Xingyi Zhou, Tianwei Yin, Vladlen Koltun, Phillip Krähenbühl.<br />
  "Global Tracking Transformers." CVPR (2022).
  [[paper](https://arxiv.org/abs/2203.13250)] 
  [[code](https://github.com/xingyizhou/GTR)]
  
- **GTELT:** Zikun Zhou, Jianqiu Chen, Wenjie Pei, Kaige Mao, Hongpeng Wang, Zhenyu He.<br />
  "Global Tracking via Ensemble of Local Trackers." CVPR (2022).
  [[paper](https://arxiv.org/abs/2203.16092)] 
  [[code](https://github.com/ZikunZhou/GTELT)]
  
- **RBO:** Feng Tang, Qiang Ling.<br />
  "Ranking-based Siamese Visual Tracking." CVPR (2022).
  [[paper](https://arxiv.org/pdf/2205.11761.pdf)] 
  [[code](https://github.com/sansanfree/RBO)]
  
- **ULAST:** Qiuhong Shen, Lei Qiao, Jinyang Guo, Peixia Li, Xin Li, Bo Li, Weitao Feng, Weihao Gan, Wei Wu, Wanli Ouyang.<br />
  "Unsupervised Learning of Accurate Siamese Tracking." CVPR (2022).
  [[paper](https://arxiv.org/abs/2204.01475)] 
  [[code](https://github.com/FlorinShum/ULAST)]
  
- **UDAT:** Junjie Ye, Changhong Fu, Guangze Zheng, Danda Pani Paudel, Guang Chen.<br />
  "Unsupervised Domain Adaptation for Nighttime Aerial Tracking." CVPR (2022).
  [[paper](https://arxiv.org/abs/2203.10541)] 
  [[code](https://github.com/vision4robotics/UDAT)]
  
- **M2Track:** Chaoda Zheng, Xu Yan, Haiming Zhang, Baoyuan Wang, Shenghui Cheng, Shuguang Cui, Zhen Li.<br />
  "Beyond 3D Siamese Tracking: A Motion-Centric Paradigm for 3D Single Object Tracking in Point Clouds." CVPR (2022).
  [[paper](https://arxiv.org/abs/2203.01730)] 
  [[code](https://github.com/Ghostish/Open3DSOT)]
  

### IJCAI 2022

- **InBN:** Mingzhe Guo, Zhipeng Zhang, Heng Fan, Liping Jing, Yilin Lyu, Bing Li, Weiming Hu.<br />
  "Learning Target-aware Representation for Visual Tracking via Informative Interactions." IJCAI (2022).
  [[paper](https://arxiv.org/abs/2201.02526)] 
  [[code](https://xxxxxxx)]
  
- **SparseTT:** Zhihong Fu, Zehua Fu, Qingjie Liu, Zehua Fu, Yunhong Wang.<br />
  "SparseTT: Visual Tracking with Sparse Transformers." IJCAI (2022).
  [[paper](https://arxiv.org/abs/2205.03776)] 
  [[code](https://github.com/fzh0917/SparseTT)]
  
- **HybTransT:** Ilchae Jung, Minji Kim, Eunhyeok Park, Bohyung Han.<br />
  "Online Hybrid Lightweight Representations Learning: Its Application to Visual Tracking." IJCAI (2022).
  [[paper](https://arxiv.org/abs/2205.11179)] 
  [[code](https://github.com/fzh0917/SparseTT)]
  
  
### MICCAI 2022

- **TLT:** Wen Tang, Han Kang, Haoyue Zhang, Pengxin Yu, Corey W. Arnold, Rongguo Zhang.<br />
  "Transformer Lesion Tracker." MICCAI (2022).
  [[paper](https://arxiv.org/abs/2206.06252)] 
  [[code](https://github.com/TangWen920812/TLT)]
  
  
### ArXiv
  
- **All-in-One:** Chunhui Zhang, Xin Sun, Li Liu, Yiqian Yang, Qiong Liu, Xi Zhou, Yanfeng Wang.<br />
  "All in One: Exploring Unified Vision-Language Tracking with Multi-Modal Alignment." ArXiv (2023).
  [[paper](https://arxiv.org/abs/2307.03373)] 
  [[code](https:/xx)]

- **COHA:** Zhiyu Zhu, Junhui Hou, Dapeng Oliver Wu.<br />
  "Cross-modal Orthogonal High-rank Augmentation for RGB-Event Transformer-trackers." ArXiv (2023).
  [[paper](https://arxiv.org/abs/2307.04129)] 
  [[code](https:/xx)]
  
- **P3DTrack:** Jiawei He, Lue Fan, Yuqi Wang, Yuntao Chen, Zehao Huang, Naiyan Wang, Zhaoxiang Zhang.<br />
  "Tracking Objects with 3D Representation from Videos." ArXiv (2023).
  [[paper](https://arxiv.org/abs/2306.05416)] 
  [[code](https:/xx)]
  
- **SAM-DA:** Liangliang Yao, Haobo Zuo, Guangze Zheng, Changhong Fu, Jia Pan.<br />
  "SAM-DA: UAV Tracks Angthing at Night with SAM-Powered Domain Adaptation." ArXiv (2023).
  [[paper](https://arxiv.org/abs/2307.01024)] 
  [[code](https:/github.com/vision4robotics/sam-da)]
  
- **SparseTrack:** Zelin Liu, Xinggang Wang, Cheng Wang, Wenyu Liu, Xiang Bai.<br />
  "SparseTrack: Multi-Object Tracking by Performing Scene Decomposition based on Pseudo-Depth." ArXiv (2023).
  [[paper](https://arxiv.org/abs/2306.05238)] 
  [[code](https://github.com/hustvl/SparseTrack)]
  
- **MACFT:** Yang Luo, Xiqing Guo, Mingtao Dong, Jin Yu.<br />
  "RGB-T Tracking Based on Mixed Attention." ArXiv (2023).
  [[paper](https://arxiv.org/abs/2304.04264)] 
  [[code](https:/xx)]
  
- **AFNet:** Jiqing Zhang, Yuanchen Wang, Wenxi Liu, Meng Li, Jinpeng Bai, Baocai Yin, Xin Yang.<br />
  "Frame-Event Alignment and Fusion Network for High Frame Rate Tracking." ArXiv (2023).
  [[paper](https://arxiv.org/abs/2305.15688)] 
  [[code](https:/xx)]
  
- **MFT:** Michal Neoral, Jonáš Šerých, Jiří Matas.<br />
  "MFT: Long-Term Tracking of Every Pixel." ArXiv (2023).
  [[paper](https://arxiv.org/abs/2305.12998)] 
  [[code](https:/xx)]
  
- **S3Track:** Fatemeh Azimi, Fahim Mannan, Felix Heide.<br />
  "S3Track: Self-supervised Tracking with Soft Assignment Flow." ArXiv (2023).
  [[paper](https://arxiv.org/abs/2305.09981)] 
  [[code](https:/xx)]
  
- **PlanarTrack:** Xinran Liu, Xiaoqiong Liu, Ziruo Yi, Xin Zhou, Thanh Le, Libo Zhang, Yan Huang, Qing Yang, Heng Fan.<br />
  "PlanarTrack: A Large-scale Challenging Benchmark for Planar Object Tracking." ArXiv (2023).
  [[paper](https://arxiv.org/abs/2303.07625)] 
  [[code](https://hengfan2010.github.io/projects/PlanarTrack/)]
  
- **TransSOT:** Janani Thangavel, Thanikasalam Kokul, Amirthalingam Ramanan, Subha Fernando.<br />
  "Transformers in Single Object Tracking: An Experimental Survey." ArXiv (2023).
  [[paper](https://arxiv.org/abs/2302.11867)] 
  [[code]()]
  
- **LaGOT:** Christoph Mayer, Martin Danelljan, Ming-Hsuan Yang, Vittorio Ferrari, Luc Van Gool, Alina Kuznetsova.<br />
  "Beyond SOT: It's Time to Track Multiple Generic Objects at Once." ArXiv (2023).
  [[paper](https://arxiv.org/abs/2212.11920)] 
  [[code]()]
  
- **ProFormer:** Yabin Zhu, Chenglong Li, Xiao Wang, Jin Tang, Zhixiang Huang.<br />
  "RGBT Tracking via Progressive Fusion Transformer with Dynamically Guided Learning." ArXiv (2023).
  [[paper](https://arxiv.org/abs/2303.14778)] 
  [[code]()]
  
- **TADS:** Xin Li, Wenjie Pei, Yaowei Wang, Zhenyu He, Huchuan Lu, Ming-Hsuan Yang.<br />
  "Self-Supervised Tracking via Target-Aware Data Synthesis." TNNLS (2023).
  [[paper](https://ieeexplore.ieee.org/document/10004981)] 
  [[code]()]
  
- **SiamTHN:** Jiahao Bao, Kaiqiang Chen, Xian Sun, Liangjin Zhao, Wenhui Diao, Menglong Yan.<br />
  "SiamTHN: Siamese Target Highlight Network for Visual Tracking." ArXiv (2023).
  [[paper](https://arxiv.org/abs/2303.12304)] 
  [[code]()]
  
- **SRNet:** Nana Fan, Qiao Liu, Xin Li, Zikun Zhou, Zhenyu He.<br />
  "Siamese Residual Network for Efficient Visual Tracking." Information Sciences (2023).
  [[paper](https://www.sciencedirect.com/science/article/abs/pii/S0020025522015778?via%3Dihub)] 
  [[code]()]
  
- **ProTrack:** Jinyu Yang, Zhe Li, Feng Zheng, Aleš Leonardis, Jingkuan Song.<br />
  "Prompting for Multi-Modal Tracking." ACM MM (2022).
  [[paper](https://arxiv.org/abs/2207.14571)] 
  [[code](https://)]
  
- **SiamTDN:** Yanjie Liang, Penghui Zhao, Yifei Hao, Hanzi Wang.<br />
  "Siamese Template Diffusion Networks for Robust Visual Tracking." ICME (2022).
  [[paper](https://ieeexplore.ieee.org/document/9859929)] 
  [[code]()]
  
- **TAT:** Kaihao Lan, Haobo Jiang, Jin Xie.<br />
  "Temporal-aware Siamese Tracker: Integrate Temporal Context for 3D Object Tracking." ACCV (2022).
  [[paper](https://openaccess.thecvf.com/content/ACCV2022/html/Lan_Temporal-aware_Siamese_Tracker_Integrate_Temporal_Context_for_3D_Object_Tracking_ACCV_2022_paper.html)] 
  [[code](https://github.com/tqsdyy/TAT)]
  
- **EgoTracks:** Hao Tang, Kevin Liang, Kristen Grauman, Matt Feiszli, Weiyao Wang.<br />
  "EgoTracks: A Long-term Egocentric Visual Object Tracking Dataset." ArXiv (2022).
  [[paper](https://arxiv.org/abs/2301.03213)] 
  [[code]()]
  
 - **COESOT:** Chuanming Tang, Xiao Wang, Ju Huang, Bo Jiang, Lin Zhu, Jianlin Zhang, Yaowei Wang, Yonghong Tian.<br />
  "Revisiting Color-Event based Tracking: A Unified Network, Dataset, and Metric." ArXiv (2022).
  [[paper](https://arxiv.org/abs/2211.11010)] 
  [[code](COESOT)]
  
- **WATB:** Fasheng Wang, Ping Cao, Fu Li, Xing Wang, Bing He, Fuming Sun.<br />
  "WATB: Wild Animal Tracking Benchmark." IJCV (2022).
  [[paper](https://link.springer.com/content/pdf/10.1007/s11263-022-01732-3.pdf?pdf=button)] 
  [[code](https://w-1995.github.io/)]
  
- **UAV2UAV:** Yong Wang, Zirong Huang, Robert Laganière, Huanlong Zhang, Lu Ding.<br />
  "A UAV to UAV tracking benchmark." KBS (2023).
  [[paper](https://www.sciencedirect.com/science/article/pii/S095070512201293X)] 
  [[code](https://github.com/hapless19/UAV2UAV-dataset)]
  
- **UOT100:** K. Panetta, L. Kezebou, V. Oludare, and S. S. Agaian.<br />
  "Comprehensive Underwater Object Tracking Benchmark Dataset and Underwater Image Enhancement With GAN." IEEE JOE (2022).
  [[paper](https://ieeexplore.ieee.org/document/9499961)] 
  [[code](https://www.kaggle.com/datasets/landrykezebou/uot100-underwater-object-tracking-dataset)]
  
- **NeighborTrack:** Yu-Hsi Chen, Chien-Yao Wang, Cheng-Yun Yang, Hung-Shuo Chang, Youn-Long Lin, Yung-Yu Chuang, Hong-Yuan Mark Liao.<br />
  "NeighborTrack: Improving Single Object Tracking by Bipartite Matching with Neighbor Tracklets." ArXiv (2022).
  [[paper](https://arxiv.org/pdf/2211.06663.pdf)] 
  [[code](https   )]
  
- **SUSHI:** Orcun Cetintas, Guillem Brasó, Laura Leal-Taixé.<br />
  "Unifying Short and Long-Term Tracking with Graph Hierarchies." ArXiv (2022).
  [[paper](https://arxiv.org/abs/2212.03038)] 
  [[code](https   )]
  
- **MTTSiam:** Ali Sekhavati, Won-Sook Lee.<br />
  "Multi-Template Temporal Siamese Network for Long-Term Object Tracking." ArXiv (2022).
  [[paper](https://arxiv.org/abs/2211.13812)] 
  [[code](https://github.com/AliGreen0/MTTSiam)]
  
- **PruningInTracking:** Saksham Aggarwal, Taneesh Gupta, Pawan Kumar Sahu, Arnav Chavan, Rishabh Tiwari, Dilip K. Prasad, Deepak K. Gupta.<br />
  "On designing light-weight object trackers through network pruning: Use CNNs or transformers?." ArXiv (2022).
  [[paper](https://arxiv.org/abs/2211.13769)] 
  [[code](https   )]
  
- **ProContEXT:** Jin-Peng Lan, Zhi-Qi Cheng, Jun-Yan He, Chenyang Li, Bin Luo, Xu Bao, Wangmeng Xiang, Yifeng Geng, Xuansong Xie.<br />
  "ProContEXT: Exploring Progressive Context Transformer for Tracking." ArXiv (2022).
  [[paper](https://arxiv.org/abs/2210.15511)] 
  [[code](https://drive.google.com/drive/folders/18kHdBNEwvbk8S4-mwHaI-mw5w6cK-pyY?usp=sharing)]
  
- **TSFMO:** Zhewen Zhang, Fuliang Wu, Yuming Qiu, Jingdong Liang, Shuiwang Li.<br />
  "Tracking Small and Fast Moving Objects: A Benchmark." ArXiv (2022).
  [[paper](https://arxiv.org/abs/2209.04284)] 
  [[code](https://github.com/CodeOfGithub/S-KeepTrack)]
  
- **SFTransT:** Chuanming Tang, Xiao Wang, Yuanchao Bai, Zhe Wu, Jianlin Zhang, Yongmei Huang.<br />
  "Learning Spatial-Frequency Transformer for Visual Object Tracking." ArXiv (2022).
  [[paper](https://arxiv.org/abs/2208.08829)] 
  [[code](https://github.com/Tchuanm/SFTransT.git)]
  
- **DMTracker:** Shang Gao, Jinyu Yang, Zhe Li, Feng Zheng, Aleš Leonardis, Jingkuan Song.<br />
  "Learning Dual-Fused Modality-Aware Representations for RGBD Tracking." ArXiv (2022).
  [[paper](https://arxiv.org/abs/2211.03055)] 
  [[code](https://github.com/ShangGaoG/DMTracker)]
  
- **AVisT:** Mubashir Noman, Wafa Al Ghallabi, Daniya Najiha, Christoph Mayer, Akshay Dudhane, Martin Danelljan, Hisham Cholakkal, Salman Khan, Luc Van Gool, Fahad Shahbaz Khan.<br />
  "AVisT: A Benchmark for Visual Object Tracking in Adverse Visibility." ArXiv (2022).
  [[paper](https://arxiv.org/abs/2208.06888)] 
  [[code](https://github.com/visionml/pytracking)]
  
- **RGBD1K:** Xue-Feng Zhu, Tianyang Xu, Zhangyong Tang, Zucheng Wu, Haodong Liu, Xiao Yang, Xiao-Jun Wu, Josef Kittler.<br />
  "RGBD1K: A Large-scale Dataset and Benchmark for RGB-D Object Tracking." ArXiv (2022).
  [[paper](https://arxiv.org/abs/2208.09787)] 
  [[code](https://github.com/xxxx)]
  
- **RGBDReview:** Jinyu Yang, Zhe Li, Song Yan, Feng Zheng, Aleš Leonardis, Joni-Kristian Kämäräinen, Ling Shao.<br />
  "RGBD Object Tracking: An In-depth Review." ArXiv (2022).
  [[paper](https://arxiv.org/abs/2203.14134)] 
  [[code](https://github.com/memoryunreal/RGBD-tracking-review)]
  
- **TOT/MKDNet:** Yabin Zhu, Chenglong Li, Yao Liu, Xiao Wang, Jin Tang, Bin Luo, Zhixiang Huang.<br />
  "Tiny Object Tracking: A Large-scale Dataset and A Baseline." ArXiv (2022).
  [[paper](https://arxiv.org/abs/2202.05659)] 
  [[code](https://github.com/mmic-lcl/Datasets-and-benchmark-code)]
  
- **WebUAV-3M:** Chunhui Zhang, Guanjie Huang, Li Liu, Shan Huang, Yinan Yang, Yuxuan Zhang, Xiang Wan, Shiming Ge.<br />
  "WebUAV-3M: A Benchmark Unveiling the Power of Million-Scale Deep UAV Tracking." ArXiv (2022).
  [[paper](https://arxiv.org/abs/2201.07425)] 
  [[code](https://github.com/983632847/WebUAV-3M)]
  
- **SOTVerse:** Shiyu Hu, Xin Zhao, Kaiqi Huang.<br />
  "SOTVerse: A User-defined Task Space of Single Object Tracking." ArXiv (2022).
  [[paper](https://arxiv.org/abs/2204.07414)] 
  [[code](http://metaverse.aitestunion.com/sotverse)]
  
- **SiamTracking4UAV:** Changhong Fu, Kunhan Lu, Guangze Zheng, Junjie Ye, Ziang Cao, Bowen Li.<br />
  "Siamese Object Tracking for Unmanned Aerial Vehicle: A Review and Comprehensive Analysis." ArXiv (2022).
  [[paper](https://arxiv.org/abs/2205.04281)] 
  [[code](https://github.com/vision4robotics/SiameseTracking4UAV)]
  
- **SOTSurvey:** Zahra Soleimanitaleb, Mohammad Ali Keyvanrad.<br />
  "Single Object Tracking: A Survey of Methods, Datasets, and Evaluation Metrics." ArXiv (2022).
  [[paper](https://arxiv.org/abs/2201.13066)] 
  
- **SOTRearch:** Ruize Han, Wei Feng, Qing Guo, Qinghua Hu.<br />
  "Single Object Tracking Research: A Survey." ArXiv (2022).
  [[paper](https://arxiv.org/abs/2204.11410)] 
  
- **VOTSurvey:** Fei Chen, Xiaodong Wang, Yunxiang Zhao, Shaohe Lv, Xin Niu.<br />
  "Visual object tracking: A survey." CVIU (2022).
  [[paper](https://www.sciencedirect.com/science/article/pii/S1077314222001011?dgcid=author)] 
    
- **HCAT:** Xin Chen, Dong Wang, Dongdong Li, Huchuan Lu.<br />
  "Efficient Visual Tracking via Hierarchical Cross-Attention Transformer." ArXiv (2022).
  [[paper](https://arxiv.org/abs/2203.13537)] 
  [[code](https://github.com/chenxin-dlut/HCAT)]
  
- **TransT-M:** Xin Chen, Bin Yan, Jiawen Zhu, Dong Wang, Huchuan Lu.<br />
  "High-Performance Transformer Tracking." ArXiv (2022).
  [[paper](https://arxiv.org/abs/2203.13533)] 
  [[code](https://github.com/chenxin-dlut/TransT-M)]
   
- **GUSOT:** Zhiruo Zhou, Hongyu Fu, Suya You, C. -C. Jay Kuo.<br />
  "GUSOT: Green and Unsupervised Single Object Tracking for Long Video Sequences" ArXiv (2022).
  [[paper](https://arxiv.org/abs/2207.07629)] 
  [[code](https://github.com/xxxxxx)]
  
- **SRRT:** Jiawen Zhu, Xin Chen, Dong Wang, Wenda Zhao, Huchuan Lu.<br />
  "SRRT: Search Region Regulation Tracking" ArXiv (2022).
  [[paper](https://arxiv.org/abs/2207.04438)] 
  [[code](https://github.com/xxxxxx)]
  
- **DIMBA:** Xiangyu Yin, Wenjie Ruan, Jonathan Fieldsend.<br />
  "DIMBA: Discretely Masked Black-Box Attack in Single Object Tracking" ArXiv (2022).
  [[paper](https://arxiv.org/abs/2207.08044)] 
  [[code](https://github.com/xxxxxxxx)]
  
- **P-SiamFC++:** Xucheng Wang, Dan Zeng, Qijun Zhao, Shuiwang Li.<br />
  "Rank-Based Filter Pruning for Real-Time UAV Tracking" ArXiv (2022).
  [[paper](https://arxiv.org/abs/2207.01768)] 
  [[code](https://github.com/visionml/pytracking)]
  
- **RGBDT:** Jinyu Yang, Zhe Li, Song Yan, Feng Zheng, Aleš Leonardis, Joni-Kristian Kämäräinen, Ling Shao.<br />
  "RGBD Object Tracking: An In-depth Review." ArXiv (2022).
  [[paper](https://arxiv.org/abs/2203.14134)] 
  [[code](https://github.com/memoryunreal/RGBD-tracking-review)]
  
- **SkeleVision:** Nilaksh Das, Sheng-Yun Peng, Duen Horng Chau.<br />
  "SkeleVision: Towards Adversarial Resiliency of Person Tracking with Multi-Task Learning." ArXiv (2022).
  [[paper](https://arxiv.org/abs/2204.00734)] 
  [[code](https://github.com/nilakshdas/SkeleVision)]
  
- **CAJMU:** Qiuhong Shen, Xin Li, Fanyang Meng, Yongsheng Liang.<br />
  "Context-aware Visual Tracking with Joint Meta-updating." ArXiv (2022).
  [[paper](https://arxiv.org/abs/2204.01513)] 
  [[code](https://github.com/xxxxxxxx)]
  
- **ResamplingNet:** Haobo Zuo, Changhong Fu, Sihang Li, Junjie Ye, and Guangze Zheng.<br />
  "ResamplingNet: End-to-End Adaptive Feature Resampling Network for Real-Time Aerial Tracking." ArXiv (2022).
  [[paper](https://arxiv.org/abs/xxxxxxxx)] 
  [[code](https://github.com/vision4robotics/ResamplingNet)]
  
- **LPAT:** Changhong Fu, Weiyu Peng, Sihang Li, Junjie Ye, and Ziang Cao.<br />
  "Local Perception-Aware Transformer for Aerial Tracking." ArXiv (2022).
  [[paper](https://arxiv.org/abs/2208.00662)] 
  [[code](https://github.com/vision4robotics/LPAT)]
  
- **AFRT:** Haobo Zuo, Changhong Fu, Sihang Li, Junjie Ye, and Guangze Zheng.<br />
  "End-to-End Feature Decontaminated Network for UAV Tracking." ArXiv (2022).
  [[paper](https://arxiv.org/abs/xxxxxxxx)] 
  [[code](https://github.com/vision4robotics/FDNT)]
  
- **FDT:** Changhong Fu, Haobo Zuo, Guangze Zheng, Junjie Ye, and Bowen Li.<br />
  "Feature-Distilled Transformer for UAV Tracking." ArXiv (2022).
  [[paper](https://arxiv.org/abs/xxxxxxxx)] 
  [[code](https://github.com/vision4robotics/FDT-tracker)]
  
- **HighlightNet:** Changhong Fu, Haolin Dong.<br />
  "HighlightNet: Highlighting Low-Light Potential Features for Real-Time UAV Tracking." ArXiv (2022).
  [[paper](https://arxiv.org/abs/xxxxxxxx)] 
  [[code](https://github.com/vision4robotics/HighlightNet)]
  
- **LAE-PVT:** Bowen Li, Yiming Li, Junjie Ye, Changhong Fu, and Hang Zhao.<br />
  "Predictive Visual Tracking: A New Benchmark and Baseline Approach." ArXiv (2022).
  [[paper](https://arxiv.org/abs/xxxxxxxx)] 
  [[code](https://github.com/vision4robotics/LAE-PVT-master)]
  
- **SiamPSA:** Guangze Zheng, Changhong Fu, Junjie Ye, Bowen Li, Geng Lu, and Jia Pan.<br />
  "SiamPSA: Siamese Object Tracking for Vision-Based UAM Approaching with Pairwise Scale-Channel Attention." ArXiv (2022).
  [[paper](https://arxiv.org/abs/xxxxxxxx)] 
  [[code](https://github.com/vision4robotics/SiamPSA)]
  
- **AdaptiveSiam:** Madhu Kiran, Le Thanh Nguyen-Meidine, Rajat Sahay, Rafael Menelau Oliveira E Cruz, Louis-Antoine Blais-Morin, Eric Granger.<br />
  "Generative Target Update for Adaptive Siamese Tracking." ArXiv (2022).
  [[paper](https://arxiv.org/abs/2202.09938)] 
  [[code](https://anonymous.4open.science/r/AdaptiveSiamese-CE78/)]
  
- **DST:** Yao Sui, Guanghui Wang, Li Zhang.<br />
  "In Defense of Subspace Tracker: Orthogonal Embedding for Visual Tracking." ArXiv (2022).
  [[paper](https://arxiv.org/abs/2204.07927)] 
  [[code](https://xxxxxxx)]
  
- **SiamLA:** Jiahao Nie, Han Wu, Zhiwei He, Yuxiang Yang, Mingyu Gao, Zhekang Dong.<br />
  "Learning Localization-aware Target Confidence for Siamese Visual Tracking." ArXiv (2022).
  [[paper](https://arxiv.org/abs/2204.14093)] 
  [[code](https://xxxxxxx/)]
  
- **DUT-Anti-UAV:** Jie Zhao, Jingshu Zhang, Dongdong Li, Dong Wang.<br />
  "Vision-based Anti-UAV Detection and Tracking." TITS (2022).
  [[paper](https://arxiv.org/abs/2205.10851)] 
  [[code](https://github.com/wangdongdut/DUT-Anti-UAV)]
  
- **CoCoLoT:** Matteo Dunnhofer, Christian Micheloni.<br />
  "CoCoLoT: Combining Complementary Trackers in Long-Term Visual Tracking." ICPR (2022).
  [[paper](https://arxiv.org/abs/2205.04261)] 
  [[code](https://xxxxxxx)]
  
- **EUSA:** Siao Liu, Zhaoyu Chen, Wei Li, Jiwei Zhu, Jiafeng Wang, Wenqiang Zhang, Zhongxue Gan.<br />
  "Efficient universal shuffle attack for visual object tracking." ICASSP (2022).
  [[paper](https://arxiv.org/abs/2203.06898)] 
  [[code](https://xxxxxxx)]
  
- **ITB:** Xin Li, Qiao Liu, Wenjie Pei, Qiuhong Shen, Yaowei Wang, Huchuan Lu, Ming-Hsuan Yang.<br />
  "An Informative Tracking Benchmark." ArXiv (2021).
  [[paper](https://arxiv.org/abs/2112.06467)] 
  [[code](https://github.com/XinLi-zn/Informative-tracking-benchmark)]
  
- **VisEvent:** Xiao Wang, Jianing Li, Lin Zhu, Zhipeng Zhang, Zhe Chen, Xin Li, Yaowei Wang, Yonghong Tian, Feng Wu.<br />
  "VisEvent: Reliable Object Tracking via Collaboration of Frame and Event Flows." ArXiv (2021).
  [[paper](https://arxiv.org/abs/2108.05015)] 
  [[code](https://sites.google.com/view/viseventtrack/)]
  
- **RPT++:** Ziang Ma, Haitao Zhang, Linyuan Wang, Jun Yin.<br />
  "RPT++: Customized Feature Representation for Siamese Visual Tracking." ArXiv (2021).
  [[paper](https://arxiv.org/abs/2110.12194)] 
  [[code](https://xxxxxxx/)]
  
- **IAT:** Mengmeng Wang, Xiaoqian Yang, Yong Liu.<br />
  "Explicitly Modeling the Discriminability for Instance-Aware Visual Object Tracking." ArXiv (2021).
  [[paper](https://arxiv.org/abs/2110.13259)] 
  [[code](https://xxxxxxx/)]
  
- **ALT:** Di Yuan, Xiaojun Chang, Qiao Liu, Dehua Wang, Zhenyu He.<br />
  "Active Learning for Deep Visual Tracking." ArXiv (2021).
  [[paper](https://arxiv.org/abs/2110.15030)] 
  [[code](https://xxxxxxx/)]
  
- **FSLT:** Jinghao Zhou, Bo Li, Peng Wang, Peixia Li, Weihao Gan, Wei Wu, Junjie Yan, Wanli Ouyang.<br />
  "Real-Time Visual Object Tracking via Few-Shot Learning." ArXiv (2021).
  [[paper](https://arxiv.org/pdf/2103.10130.pdf)] 
  [[code](https://xxxxxxx/)]
  
- **DML:** Jinghao Zhou, Bo Li, Lei Qiao, Peng Wang, Weihao Gan, Wei Wu, Junjie Yan, Wanli Ouyang.<br />
  "Higher Performance Visual Tracking with Dual-Modal Localization." ArXiv (2021).
  [[paper](https://arxiv.org/pdf/2103.10089.pdf)] 
  [[code](https://xxxxxxx/)]
  
- **TREG:** Yutao Cui, Cheng Jiang, Limin Wang, Gangshan Wu.<br />
  "Target Transformed Regression for Accurate Tracking." ArXiv (2021).
  [[paper](https://arxiv.org/pdf/2104.00403.pdf)] 
  [[code](https://github.com/MCG-NJU/TREG)]
  
- **SiamSTM:** Jinpu Zhang, Yuehuan Wang.<br />
  "Spatio-Temporal Matching for Siamese Visual Tracking." ArXiv (2021).
  [[paper](https://arxiv.org/pdf/2105.02408.pdf)] 
  [[code](https://xxxxxxx/)]
  
- **TrTr:** Moju Zhao, Kei Okada, Masayuki Inaba.<br />
  "TrTr: Visual Tracking with Transformer." ArXiv (2021).
  [[paper](https://arxiv.org/pdf/2105.03817.pdf)] 
  [[code](https://github.com/tongtybj/TrTr)]

- **TS-RCN:** Ning Zhang, Jingen Liu, Ke Wang, Dan Zeng, Tao Mei.<br />
  "Robust Visual Object Tracking with Two-Stream Residual Convolutional Networks." ArXiv (2020).
  [[paper](https://arxiv.org/pdf/2005.06536.pdf)] 
  [[code](https://github.com/xxxxx/xxxx)]
  
- **DMV:** Gunhee Nam, Seoung Wug Oh, Joon-Young Lee, Seon Joo Kim.<br />
  "DMV: Visual Object Tracking via Part-level Dense Memory and Voting-based Retrieval." ArXiv (2020).
  [[paper](https://arxiv.org/abs/2003.09171v1)] 
  [[code](https://github.com/xxxxx/xxxx)]
  
- **FCOT:** Yutao Cui, Cheng Jiang, Limin Wang, Gangshan Wu.<br />
  "Fully Convolutional Online Tracking." ArXiv (2020).
  [[paper](https://arxiv.org/abs/2004.07109)] 
  [[code](https://github.com/MCG-NJU/FCOT)]
  
  
### AAAI 2022

- **HDN:** Xinrui Zhan, Yueran Liu, jianke Zhu, Yang Li.<br />
  "Homography Decomposition Networks for Planar Object Tracking." AAAI (2022).
  [[paper](https://arxiv.org/pdf/2112.07909.pdf)] 
  [[code](https://github.com/zhanxinrui/HDN)]

- **MArMOT:** Chenglong Li, Tianhao Zhu, Lei Liu, Xiaonan Si, Zilin Fan, Sulan Zhai.<br />
  "Cross-Modal Object Tracking: Modality-Aware Representations and a Unified Benchmark." AAAI (2022).
  [[paper](https://arxiv.org/abs/2111.04264)] 
  [[code](https://github.com/xxxxx/MArMOT)]

- **APFNet:** Yun Xiao, Mengmeng Yang, Chenglong Li, Lei Liu, Jin Tang.<br />
  "Attribute-based Progressive Fusion Network for RGBT Tracking." AAAI (2022).
  [[paper](https://github.com/yangmengmeng1997/APFNet/tree/main/Paper)] 
  [[code](https://github.com/yangmengmeng1997/APFNet)]

- **TAV:** Tahar Allouche, Jerome Lang, Florian Yger.<br />
  "Truth-Tracking via Approval Voting: Size Matters." AAAI (2022).
  [[paper](https://arxiv.org/abs/2112.04387)] 
  [[code](https://github.com/zhanxinrui/HDN)]
  
  
### ICLR 2022

- **FSBA:** Yiming Li, Haoxiang Zhong, Xingjun Ma, Yong Jiang, Shu-Tao Xia.<br />
  "Few-Shot Backdoor Attacks on Visual Object Tracking." ICLR (2022).
  [[paper](https://openreview.net/pdf?id=qSV5CuSaK_a)] 
  [[code](https://www.dropbox.com/s/nfg7en8azc1cvz3/codes_FSBA_ICLR22.zip?dl=0)]
  
  
### ICRA 2022

- **Ad2Attack:** Changhong Fu, Sihang Li, Xinnan Yuan, Junjie Ye, Ziang Cao, Fangqiang Ding.<br />
  "Ad2Attack: Adaptive Adversarial Attack on Real-Time UAV Tracking." ICRA (2022).
  [[paper](https://arxiv.org/abs/2203.01516)] 
  [[code](https://github.com/vision4robotics/Ad2Attack)]
 
- **SCT:** Junjie Ye, Changhong Fu, Ziang Cao, Shan An, Guangze Zheng, Bowen Li.<br />
  "Tracker Meets Night: A Transformer Enhancer for UAV Tracking." ICRA/RAL (2022).
  [[paper](https://ieeexplore.ieee.org/document/9696362)] 
  [[code](https://github.com/vision4robotics/SCT)]
 
 
### WACV 2022

- **SiamTPN:** Daitao Xing, Nikolaos Evangeliou, Athanasios Tsoukalas, Anthony Tzes.<br />
  "Siamese Transformer Pyramid Networks for Real-Time UAV Tracking." WACV (2022).
  [[paper](https://arxiv.org/pdf/2110.08822.pdf)] 
  [[code](https://github.com/RISC-NYUAD/SiamTPNTracker)]
  
### ICCV 2021

- **STARK:** Bin Yan, Houwen Peng, Jianlong Fu, Dong Wang, Huchuan Lu.<br />
  "Learning Spatio-Temporal Transformer for Visual Tracking." ICCV (2021).
  [[paper](https://arxiv.org/pdf/2103.17154.pdf)] 
  [[code](https://github.com/researchmm/Stark)]
  
- **AutoMatch:**  Zhang Zhipeng, Liu Yihao, Wang Xiao, Li Bing, Hu Weiming. <br />
  "Learn to Match: Automatic Matching Network Design for Visual Tracking." ICCV (2021).
  [[paper](https://arxiv.org/pdf/2108.00803.pdf)]
  [[code](https://github.com/JudasDie/SOTS)]
  
- **DDT:** Bin Yu, Ming Tang, Linyu Zheng, Guibo Zhu, Jinqiao Wang.<br />
  "High-Performance Discriminative Tracking with Transformers." ICCV (2021).
  [[paper](https://openaccess.thecvf.com/content/ICCV2021/papers/Yu_High-Performance_Discriminative_Tracking_With_Transformers_ICCV_2021_paper.pdf)] 
  [[code](https://github.com/xxxx/xxxx)]
  
- **HiFT:**  Ziang Cao, Changhong Fu, Junjie Ye, Bowen Li, Yiming Li. <br />
  "HiFT: Hierarchical Feature Transformer for Aerial Tracking." ICCV (2021).
  [[paper](https://arxiv.org/pdf/2108.00202.pdf)]
  [[code](https://github.com/vision4robotics/HiFT)]
  
- **DualTFR:**  Fei Xie, Chunyu Wang, Guangting Wang, Wankou Yang, Wenjun Zeng. <br />
  "Learning Tracking Representations via Dual-Branch Fully Transformer Networks." ICCVW (2021).
  [[paper](https://arxiv.org/abs/2112.02571)]
  [[code](https://github.com/phiphiphi31/DualTFR)]
  
- **DMB:**  Fei Xie, Wankou Yang, Kaihua Zhang, Bo Liu, Wanli Xue, Wangmeng Zuo. <br /> 
  "Learning Spatio-Appearance Memory Network for High-Performance Visual Tracking." ICCVW (2021).
  [[paper](https://arxiv.org/pdf/2009.09669.pdf)]
  [[code](https://github.com/phiphiphi31/DMB)]

- **KeepTrack:** Christoph Mayer, Martin Danelljan, Danda Pani Paudel, Luc Van Gool.<br />
  "Learning Target Candidate Association to Keep Track of What Not to Track." ICCV (2021).
  [[paper](https://arxiv.org/abs/2103.16556)] 
  [[code](https://github.com/visionml/pytracking)]

- **SAOT:** Zikun Zhou, Wenjie Pei, Xin Li, Hongpeng Wang, Feng Zheng, Zhenyu He. <br />
  "Saliency-Associated Object Tracking." ICCV (2021).
  [[paper](https://arxiv.org/pdf/2108.03637.pdf)]
  [[code](https://github.com/ZikunZhou/SAOT)]
 
- **MLVSNet:** Zhoutao Wang, Qian Xie, Yu-Kun Lai, Jing Wu, Kun Long , Jun Wang. <br />
  "MLVSNet: Multi-level Voting Siamese Network for 3D Visual Tracking." ICCV (2021).
  [[paper](https://openaccess.thecvf.com/content/ICCV2021/papers/Wang_MLVSNet_Multi-Level_Voting_Siamese_Network_for_3D_Visual_Tracking_ICCV_2021_paper.pdf)]
  [[code](https://github.com/CodeWZT/MLVSNet)]
  
 - **EFTrack:** Jiqing Zhang, Xin Yang, Yingkai Fu, Xiaopeng Wei, Baocai Yin, Bo Dong. <br />
  "Object Tracking by Jointly Exploiting Frame and Event Domain." ICCV (2021).
  [[paper](https://arxiv.org/abs/2109.09052)]
  [[code](https://github.com/Jee-King/ICCV2021_Event_Frame_Tracking)]
  
 - **Box2Mask:** Bin Zhao, Goutam Bhat, Martin Danelljan, Luc Van Gool, Radu Timofte. <br />
  "Generating Masks from Boxes by Mining Spatio-Temporal Consistencies in Videos." ICCV (2021).
  [[paper](https://arxiv.org/abs/2101.02196)]
  [[code](https://github.com/visionml/pytracking)]
  
- **DepthTrack:** Song Yan, Jinyu Yang, Jani Käpylä, Feng Zheng, Aleš Leonardis, Joni-Kristian Kämäräinen. <br />
  "DepthTrack : Unveiling the Power of RGBD Tracking." ICCV (2021).
  [[paper](https://arxiv.org/abs/2108.13962)]
  [[code](https://github.com/xiaozai/DeT)]
  
- **USOT:** Jilai Zheng, Chao Ma, Houwen Peng, Xiaokang Yang. <br />
  "Learning to Track Objects from Unlabeled Videos." ICCV (2021).
  [[paper](https://arxiv.org/abs/2108.12711)]
  [[code](https://github.com/VISION-SJTU/USOT)]
  
- **TOTB:** Heng Fan, Halady Akhilesha Miththanthaya, Harshit, Siranjiv Ramana Rajan, Xiaoqiong Liu, Zhilin Zou, Yuewei Lin, Haibin Ling. <br />
  "Transparent Object Tracking Benchmark." ICCV (2021).
  [[paper](https://arxiv.org/abs/2011.10875)]
  [[code](https://hengfan2010.github.io/projects/TOTB/)]
  
- **TREK-150:** Matteo Dunnhofer, Antonino Furnari, Giovanni Maria Farinella, Christian Micheloni. <br />
  "Is First Person Vision Challenging for Object Tracking?." ICCVW (2021).
  [[paper](https://arxiv.org/abs/2108.13665)]
  [[code](https://machinelearning.uniud.it/datasets/trek150/)]
  [[toolkit](https://github.com/matteo-dunnhofer/TREK-150-toolkit)]
  
- **VASR:** Kenan Dai, Jie Zhao, Lijun Wang, Dong Wang, Jianhua Li, Huchuan Lu, Xuesheng Qian, Xiaoyun Yang. <br />
  "Video Annotation for Visual Tracking via Selection and Refinement." ICCV (2021).
  [[paper](https://arxiv.org/pdf/2108.03821.pdf)]
  [[code](https://github.com/Daikenan/VASR)]
  
- **BAT:** Chaoda Zheng, Xu Yan, Jiantao Gao, Weibing Zhao, Wei Zhang, Zhen Li, Shuguang Cui. <br />
  "Box-Aware Feature Enhancement for Single Object Tracking on Point Clouds." ICCV (2021).
  [[paper](https://arxiv.org/pdf/2108.04728.pdf)]
  [[code](https://github.com/Ghostish/BAT)]
  
- **ABA:** Qing Guo, Ziyi Cheng, Felix Juefei-Xu, Lei Ma, Xiaofei Xie, Yang Liu, Jianjun Zhao. <br />
  "Learning to Adversarially Blur Visual Object Tracking." ICCV (2021).
  [[paper](https://arxiv.org/abs/2107.12085)]
  [[code](https://github.com/tsingqguo/ABA)]
  
  
### CVPR 2021

- **TransT:** Xin Chen, Bin Yan, Jiawen Zhu, Dong Wang, Xiaoyun yang, Huchuan Lu. <br />
  "Transformer Tracking." CVPR (2021).
  [[paper](https://arxiv.org/abs/2103.15436)]
  [[code](https://github.com/chenxin-dlut/TransT)]
  
- **Alpha-Refine:** Bin Yan, Xinyu Zhang, Dong Wang, Huchuan Lu, Xiaoyun Yang. <br />
  "Alpha-Refine: Boosting Tracking Performance by Precise Bounding Box Estimation." CVPR (2021).
  [[paper](https://arxiv.org/pdf/1911.12836.pdf)]
  [[code](https://github.com/MasterBin-IIAU/AlphaRefine)]
  
- **LightTrack:** Bin Yan, Houwen Peng, Kan Wu, Dong Wang, Jianlong Fu, Huchuan Lu. <br />
  "LightTrack: Finding Lightweight Neural Networks for Object Tracking via One-Shot Architecture Search." CVPR (2021).
  [[paper](https://arxiv.org/abs/2104.14545)]
  [[code](https://github.com/cvpr-2021/lighttrack)]
  
- **TrTrack:** Ning Wang, Wengang Zhou, Jie Wang, Houqiang Li. <br />
  "Transformer Meets Tracker: Exploiting Temporal Context for Robust Visual Tracking." CVPR (2021).
  [[paper](https://arxiv.org/pdf/2103.11681.pdf)]
  [[code](https://github.com/594422814/TransformerTrack)]
  
- **STMTrack:** Zhihong Fu, Qingjie Liu, Zehua Fu, Yunhong Wang. <br />
  "STMTrack: Template-free Visual Tracking with Space-time Memory Networks." CVPR (2021).
  [[paper](https://arxiv.org/abs/2104.00324)]
  [[code](https://github.com/fzh0917/STMTrack)]
  
- **SiamGAT:** Dongyan Guo, Yanyan Shao, Ying Cui, Zhenhua Wang, Liyan Zhang, Chunhua Shen.<br />
  "Graph Attention Tracking." CVPR (2021).
  [[paper](https://arxiv.org/abs/2011.11204)] 
  [[code](https://github.com/ohhhyeahhh/SiamGAT)]
  
- **SiamACM:** Wencheng Han, Xingping Dong, Fahad Shahbaz Khan, Ling Shao, Jianbing Shen.<br />
  "Learning to Fuse Asymmetric Feature Maps in Siamese Trackers." CVPR (2021).
  [[paper](https://arxiv.org/pdf/2012.02776.pdf)] 
  [[code](https://github.com/wencheng256/SiamBAN-ACM)]
  
- **PST:** Gunhee Nam, Miran Heo, Seoung Wug Oh, Joon-Young Lee, Seon Joo Kim.<br />
  "Polygonal Point Set Tracking." CVPR (2021).
  [[paper](https://openaccess.thecvf.com/content/CVPR2021/papers/Nam_Polygonal_Point_Set_Tracking_CVPR_2021_paper.pdf)] 
  [[code](https://github.com/PST)]
  
- **PUL:** Qiangqiang Wu, Jia Wan, Antoni B. Chan. <br />
  "Progressive Unsupervised Learning for Visual Object Tracking." CVPR (2021).
  [[paper](https://openaccess.thecvf.com/content/CVPR2021/papers/Wu_Progressive_Unsupervised_Learning_for_Visual_Object_Tracking_CVPR_2021_paper.pdf)]
  [[code](https://github.com/PUL)]
  
- **CapsuleRRT:** Ding Ma, Xiangqian Wu. <br />
  "CapsuleRRT: Relationships-Aware Regression Tracking via Capsules." CVPR (2021).
  [[paper](https://openaccess.thecvf.com/content/CVPR2021/papers/Ma_CapsuleRRT_Relationships-Aware_Regression_Tracking_via_Capsules_CVPR_2021_paper.pdf)]
  [[code](https://github.com/CapsuleRRT)]
  
- **Semi-Track:** Yang Fu, Sifei Liu, Umar Iqbal, Shalini De Mello, Humphrey Shi, Jan Kautz.<br />
  "Learning to Track Instances without Video Annotations." CVPR (2021).
  [[paper](https://arxiv.org/pdf/2104.00287.pdf)] 
  [[code](https://oasisyang.github.io/projects/semi-track/index.html)]

- **RE-Siam:** Deepak K. Gupta, Devanshu Arya, Efstratios Gavves. <br />
  "Rotation Equivariant Siamese Networks for Tracking." CVPR (2021).
  [[paper](https://arxiv.org/abs/2012.13078)]
  [[code](https://github.com/dkgupta90/re-siamnet)]
  
- **SiamNLP:** Qi Feng, Vitaly Ablavsky, Qinxun Bai, Stan Sclaroff. <br />
  "Siamese Natural Language Tracker: Tracking by Natural Language Descriptions with Siamese Trackers." CVPR (2021).
  [[paper](https://arxiv.org/abs/1912.02048v2)]
  [[code](https://github.com/fredfung007/snlt)]
  
- **LangTrackBenchmark:** Xiao Wang, Xiujun Shu, Zhipeng Zhang, Bo Jiang, Yaowei Wang, Yonghong Tian, Feng Wu. <br />
  "Towards More Flexible and Accurate Object Tracking with Natural Language: Algorithms and Benchmark." CVPR (2021).
  [[paper](https://arxiv.org/pdf/2103.16746.pdf)]
  [[code](https://sites.google.com/view/langtrackbenchmark/)]
  
- **DroneCrowd:** Longyin Wen, Dawei Du, Pengfei Zhu, Qinghua Hu, Qilong Wang, Liefeng Bo, Siwei Lyu. <br />
  "Detection, Tracking, and Counting Meets Drones in Crowds: A Benchmark." CVPR (2021).
  [[paper](https://arxiv.org/pdf/2105.02440.pdf)]
  [[code](https://github.com/VisDrone/DroneCrowd)]
  
- **DMTrack:** Zikai Zhang, Bineng Zhong, Shengping Zhang, Zhenjun Tang, Xin Liu, Zhaoxiang Zhang. <br />
  "Distractor-Aware Fast Tracking via Dynamic Convolutions and MOT Philosophy." CVPR (2021).
  [[paper](https://arxiv.org/abs/2104.12041)]
  [[code](https://github.com/hqucv/dmtrack)]
  
- **LF-Siam:** Siyuan Cheng, Bineng Zhong, Guorong Li, Xin Liu, Zhenjun Tang, Xianxian Li, Jing Wang. <br />
  "Learning to Filter: Siamese Relation Network for Robust Tracking." CVPR (2021).
  [[paper](https://arxiv.org/abs/2104.00829)]
  [[code](https://github.com/hqucv/siamrn)]
  
- **IoU Attack:** Shuai Jia, Yibing Song, Chao Ma, Xiaokang Yang. <br />
  "IoU Attack: Towards Temporally Coherent Black-Box Adversarial Attack for Visual Object Tracking." CVPR (2021).
  [[paper](https://arxiv.org/abs/2103.14938)]
  [[code](https://github.com/VISION-SJTU/IoUattack)]
  
- **MeanShift++:** Jennifer Jang, Heinrich Jiang. <br />
  "MeanShift++: Extremely Fast Mode-Seeking With Applications to Segmentation and Object Tracking." CVPR (2021).
  [[paper](https://openaccess.thecvf.com/content/CVPR2021/papers/Jang_MeanShift_Extremely_Fast_Mode-Seeking_With_Applications_to_Segmentation_and_Object_CVPR_2021_paper.pdf)]
  [[code](https://github.com/MeanShift++)]
  
  
### IROS 2021

- **CRACT:** Heng Fan, Haibin Ling.<br />
  "CRACT: Cascaded Regression-Align-Classification for Robust Visual Tracking." IROS (2020).
  [[paper](https://arxiv.org/abs/2011.12483)] 

- **SiamAPN++:** Ziang Cao, Changhong Fu, Junjie Ye, Bowen Li, Yiming Li.<br />
  "SiamAPN++: Siamese Attentional Aggregation Network for Real-Time UAV Tracking." IROS (2021).
  [[paper](https://arxiv.org/pdf/2106.08816.pdf)] 
  [[code](https://github.com/vision4robotics/SiamAPN)]

- **DarkLighter:** Junjie Ye, Changhong Fu, Guangze Zheng, Ziang Cao, Bowen Li.<br />
  "DarkLighter: Light Up the Darkness for UAV Tracking." IROS (2021).
  [[paper](https://arxiv.org/pdf/2107.14389.pdf)] 
  [[code](https://github.com/vision4robotics/DarkLighter)]
  
- **PTT:** Jiayao Shan, Sifan Zhou, Zheng Fang, Yubo Cui.<br />
  "PTT: Point-Track-Transformer Module for 3D Single Object Tracking in Point Clouds." IROS (2021).
  [[paper](https://arxiv.org/abs/2108.06455)] 
  [[code](https://github.com/shanjiayao/PTT)]
  
  
### NeurIPS 2021

- **PathTrack:** Drew Linsley, Girik Malik, Junkyung Kim, Lakshmi Narasimhan Govindarajan, Ennio Mingolla, Thomas Serre.<br />
  "Tracking Without Re-recognition in Humans and Machines." NeurIPS (2021).
  [[paper](https://proceedings.neurips.cc/paper/2021/hash/a2557a7b2e94197ff767970b67041697-Abstract.html)] 
  [[code](http://bit.ly/InTcircuit)]
  
- **UniTrack:** Zhongdao Wang, Hengshuang Zhao, Ya-Li Li, Shengjin Wang, Philip Torr, Luca Bertinetto.<br />
  "Do Different Tracking Tasks Require Different Appearance Models?." NeurIPS (2021).
  [[paper](https://proceedings.neurips.cc/paper/2021/hash/06997f04a7db92466a2baa6ebc8b872d-Abstract.html)] 
  [[code](https://zhongdao.github.io/UniTrack/)]

  
### WACV 2021

- **MART:** Heng Fan, Haibin Ling.<br />
  "MART: Motion-Aware Recurrent Neural Network for Robust Visual Tracking." WACV (2021).
  [[paper](https://openaccess.thecvf.com/content/WACV2021/papers/Fan_MART_Motion-Aware_Recurrent_Neural_Network_for_Robust_Visual_Tracking_WACV_2021_paper.pdf)] 
  [[code](https://hengfan2010.github.io/projects/MART/MART.htm)]
  
- **SiamSE:** Ivan Sosnovik, Artem Moskalev, Arnold Smeulders.<br />
  "Scale Equivariance Improves Siamese Tracking." WACV (2021).
  [[paper](https://arxiv.org/pdf/2007.09115.pdf)] 
  [[code](https://github.com/ISosnovik/SiamSE)]
  
- **TracKlinic:** Heng Fan, Fan Yang, Peng Chu, Yuewei Lin, Lin Yuan, Haibin Ling. <br />
  "TracKlinic: Diagnosis of Challenge Factors in Visual Tracking." WACV (2021).
  [[paper](https://arxiv.org/abs/1911.07959)]
  [[code](https://hengfan2010.github.io/projects/TracKlinic/TracKlinic.htm.)]
  
  
### AAAI 2021

- **MUG:** Lijun Zhou, Antoine Ledent, Qintao Hu, Ting Liu, Jianlin Zhang, Marius Kloft.<br />
  "Model Uncertainty Guides Visual Object Tracking." AAAI (2021).
  [[paper](https://ojs.aaai.org/index.php/AAAI/article/view/16473)] 
  
- **UPA:** Li Ding, Yongwei Wang, Kaiwen Yuan, Minyang Jiang, Ping Wang, Hua Huang, Z. Jane Wang. <br />
  "Towards Universal Physical Attacks on Single Object Tracking." AAAI (2021).
  [[paper](https://www.aaai.org/AAAI21Papers/AAAI-2606.DingL.pdf)]

- **PACNet:** Dawei Zhang, Zhonglong Zheng, Riheng Jia, Minglu Li.<br />
  "Visual Tracking via Hierarchical Deep Reinforcement Learning." AAAI (2021).
  [[paper](https://ojs.aaai.org/index.php/AAAI/article/view/16443)] 
  
- **MSANet:** Xuesong Chen, Canmiao Fu, Feng Zheng, Yong Zhao, Hongsheng Li, Ping Luo, Guo-Jun Qi. <br />
  "A Unified Multi-Scenario Attacking Network for Visual Object Tracking." AAAI (2021).
  [[paper](https://ojs.aaai.org/index.php/AAAI/article/view/16195)]
  

### Others 2021

- **SiamAPN:** Changhong Fu, Ziang Cao, Yiming Li, Junjie Ye, Chen Feng.<br />
  "Onboard Real-Time Aerial Tracking with Efficient Siamese Anchor Proposal Network." IEEE TGRS (2021).
  [[paper](https://ieeexplore.ieee.org/document/9477413)] 
  [[code](https://github.com/vision4robotics/SiamAPN)]
  
- **SiamGAN:** Yifei Zhou, Jing Li, Jun Chang, Yafu Xiao, Jun Wan, Hang Sun.<br />
  "Siamese Guided Anchoring Network for Visual Tracking." IEEE IJCNN (2021).
  [[paper](https://ieeexplore.ieee.org/document/9533985)] 
  [[code](https://github.com/xxxxx.xx)]
  
- **τ:** Matteo Dunnhofer, Kristian Simonato, Christian Micheloni.<br />
  "Combining complementary trackers for enhanced long-term visual object tracking." IVC (2022).
  [[paper](https://www.sciencedirect.com/science/article/pii/S0262885622000774?via%3Dihub)] 
  [[code](https://github.com/xxxxx.xx)]
  
- **CCR:** Shiming Ge, Chunhui Zhang, Shikun Li, Dan Zeng, Dacheng Tao.<br />
  "Cascaded Correlation Refinement for Robust Deep Tracking." IEEE TNNLS (2021).
  [[paper](https://ieeexplore.ieee.org/document/9069312)] 
  [[code](https://github.com/983632847/CCR)]
  
- **PCDHV:** Ying Wang, Tingfa Xu, Jianan Li, Shenwang Jiang, Junjie Chen.<br />
  "Pyramid Correlation based Deep Hough Voting for Visual Object Tracking." ACML (2021).
  [[paper](https://arxiv.org/abs/2110.07994)] 
  
- **TrackMLP:** Tianyu Zhu, Rongkai Ma, Mehrtash Harandi, Tom Drummond. <br />
  "Learning Online for Unified Segmentation and Tracking Models." IJCNN (2021).
  [[paper](https://arxiv.org/abs/2111.06994)]

- **TAPL:** Wei han, Hantao Huang, Xiaoxi Yu.<br />
  "TAPL: Dynamic Part-based Visual Tracking via Attention-guided Part Localization." BMVC (2021).
  [[paper](https://arxiv.org/abs/2110.13027)] 
 
- **CHASE:** Seyed Mojtaba Marvasti-Zadeh, Javad Khaghani, Li Cheng, Hossein Ghanei-Yakhdan, Shohreh Kasaei.<br />
  "CHASE: Robust Visual Tracking via Cell-Level Differentiable Neural Architecture Search." BMVC (2021).
  [[paper](https://arxiv.org/abs/2107.03463)] 
  
### ECCV 2020

- **Ocean:** Zhipeng Zhang, Houwen Peng, Jianlong Fu, Bing Li, Weiming Hu. <br />
  "Ocean: Object-aware Anchor-free Tracking." ECCV (2020).
  [[paper](https://arxiv.org/pdf/2006.10721.pdf)]
  [[code](https://github.com/researchmm/TracKit)]
  
- **KYS:** Goutam Bhat, Martin Danelljan, Luc Van Gool, Radu Timofte. <br />
  "Know Your Surroundings: Exploiting Scene Information for Object Tracking." ECCV (2020).
  [[paper](https://arxiv.org/pdf/2003.11014v1.pdf)]
  [[code](https://github.com/visionml/pytracking)]
  
- **PGNet:** Bingyan Liao, Chenye Wang, Yayun Wang, Yaonong Wang, Jun Yin. <br />
  "PG-Net: Pixel to Global Matching Network for Visual Tracking." ECCV (2020).
  [[paper](https://arxiv.org/abs/2003.11014)]
  
- **STN:** Yuan Liu, Ruoteng Li, Yu Cheng, Robby T.Tan, Xiubao Sui. <br />
  "Object Tracking using Spatio-Temporal Networks for Future Prediction Location." ECCV (2020).
  [[paper](https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123670001.pdf)]
  
- **RPT:** Ziang Ma, Linyuan Wang, Haitao Zhang, Wei Lu, Jun Yin. <br />
  "RPT: Learning Point Set Representation for Siamese Visual Tracking." ECCVW (2020).
  [[paper](https://arxiv.org/abs/2008.03467)]
  [[code](https://github.com/zhanght021/RPT)]
  
- **CenterTrack:** Xingyi Zhou, Vladlen Koltun, and Philipp Krahenbuhl. <br />
  "Tracking objects as points." ECCV (2020).
  [[paper](https://arxiv.org/abs/2004.01177)]
  [[code](https://github.com/xingyizhou/CenterTrack)]
  
- **PointTracker:** Zhenbo Xu, Wei Zhang, Xiao Tan, Wei Yang, Huan Huang, Shilei Wen, Errui Ding, Liusheng Huang. <br />
  "Segment as Points for Efficient Online Multi-Object Tracking and Segmentation." ECCV (2020).
  [[paper](https://arxiv.org/abs/2007.01550)]
  [[code](https://github.com/detectRecog/PointTrack)]
  
- **DCFST:** Linyu Zheng, Ming Tang, Yingying Chen, Jinqiao Wang, Hanqing Lu. <br />
  "Learning Feature Embeddings for Discriminant Model based Tracking." ECCV (2020).
  [[paper](https://arxiv.org/abs/1906.10414)]
  [[code](https://github.com/noneUmbrella/DCFST)]
  
- **CLNet:** Xingping Dong, Jianbing Shen, Ling Shao, Fatih Porikli. <br />
  "CLNet: A Compact Latent Network for Fast Adjusting Siamese Tracker." ECCV (2020).
  [[paper](https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123650375.pdf)]
  [[code](https://github.com/xingpingdong/CLNet-tracking)]
  
- **RTAA:** Shuai Jia, Chao Ma, Yibing Song, Xiaokang Yang. <br />
  "Robust Tracking against Adversarial Attacks." ECCV (2020).
  [[paper](https://arxiv.org/abs/2007.09919)]
  [[code](https://github.com/joshuajss/RTAA)]
  
- **EAA:** Siyuan Liang, Xingxing Wei, Siyuan Yao, Xiaochun Cao. <br />
  "Efficient Adversarial Attacks for Visual Object Tracking." ECCV (2020).
  [[paper](https://arxiv.org/abs/2008.00217)]

- **SPARK:** Qing Guo, Xiaofei Xie, Felix Juefei-Xu, Lei Ma, Zhongguo Li, Wanli Xue, Wei Feng, Yang Liu. <br />
  "SPARK: Spatial-aware Online Incremental Attack Against Visual Tracking." ECCV (2020).
  [[paper](https://arxiv.org/pdf/1910.08681.pdf)]
  
- **CAT:** Chenglong Li, Lei Liu, Andong Lu, Qing Ji, Jin Tang. <br />
  "Challenge-Aware RGBT Tracking." ECCV (2020).
  [[paper](https://arxiv.org/abs/2007.13143)]

- **JDE:** Zhongdao Wang, Liang Zheng, Yixuan Liu, Shengjin Wang. <br />
  "Towards Real-Time Multi-Object Tracking." ECCV (2020).
  [[paper](https://arxiv.org/pdf/1909.12605v1.pdf)]
  [[code](https://gitee.com/mat026/Towards-Realtime-MOT)]
  
- **Chained-Tracker:** Jinlong Peng, Changan Wang, Fangbin Wan, Yang Wu, Yabiao Wang, Ying Tai, Chengjie Wang, Jilin Li, Feiyue Huang, Yanwei Fu. <br />
  "Chained-Tracker: Chaining Paired Attentive Regression Results for End-to-End Joint Multiple-Object Detection and Tracking." ECCV (2020).
  [[paper](https://arxiv.org/pdf/2007.14557.pdf)]
  [[code](https://github.com/pjl1995/CTracker)]
  
- **TAO:** Achal Dave, Tarasha Khurana, Pavel Tokmakov, Cordelia Schmid, Deva Ramanan. <br />
  "TAO: A Large-scale Benchmark for Tracking Any Object." ECCV (2020).
  [[paper](https://arxiv.org/abs/2005.10356)]
  [[code](http://taodataset.org/)]

### CVPR2020

* **MAML:** Guangting Wang, Chong Luo, Xiaoyan Sun, Zhiwei Xiong, Wenjun Zeng.<br />
  "Tracking by Instance Detection: A Meta-Learning Approach." CVPR (2020 **Oral**).
  [[paper](https://arxiv.org/pdf/2004.00830v1.pdf)]

* **Siam R-CNN:** Paul Voigtlaender, Jonathon Luiten, Philip H.S. Torr, Bastian Leibe.<br />
  "Siam R-CNN: Visual Tracking by Re-Detection." CVPR (2020).
  [[BoLTVOS](https://arxiv.org/pdf/1904.04552.pdf)] 
  [[paper](https://arxiv.org/pdf/1911.12836.pdf)] 
  [[code](https://www.vision.rwth-aachen.de/page/siamrcnn)]

* **D3S:** Alan Lukežič, Jiří Matas, Matej Kristan.<br />
  "D3S – A Discriminative Single Shot Segmentation Tracker." CVPR (2020).
  [[paper](http://arxiv.org/pdf/1911.08862v2.pdf)]
  [[code](https://github.com/alanlukezic/d3s)]

* **PrDiMP:** Martin Danelljan, Luc Van Gool, Radu Timofte.<br />
  "Probabilistic Regression for Visual Tracking." CVPR (2020).
  [[paper](https://arxiv.org/pdf/2003.12565v1.pdf)]
  [[code](https://github.com/visionml/pytracking)]

* **ROAM:** Tianyu Yang, Pengfei Xu, Runbo Hu, Hua Chai, Antoni B. Chan.<br />
  "ROAM: Recurrently Optimizing Tracking Model." CVPR (2020).
  [[paper](https://arxiv.org/pdf/1907.12006v3.pdf)]
  [[code](https://github.com/skyoung/ROAM)]

* **AutoTrack:** Yiming Li, Changhong Fu, Fangqiang Ding, Ziyuan Huang, Geng Lu.<br />
  "AutoTrack: Towards High-Performance Visual Tracking for UAV with Automatic Spatio-Temporal Regularization." CVPR (2020).
  [[paper](https://arxiv.org/pdf/2003.12949.pdf)]
  [[code](https://github.com/vision4robotics/AutoTrack)]

* **SiamBAN:** Zedu Chen, Bineng Zhong, Guorong Li, Shengping Zhang, Rongrong Ji.<br />
  "Siamese Box Adaptive Network for Visual Tracking." CVPR (2020).
  [[paper](http://arxiv.org/pdf/1911.08862v2.pdf)]
  [[code](https://github.com/hqucv/siamban)]

* **SiamCAR:** Dongyan Guo, Jun Wang, Ying Cui, Zhenhua Wang, Shengyong Chen.<br />
  "SiamCAR: Siamese Fully Convolutional Classification and Regression for Visual Tracking." CVPR (2020).
  [[paper](https://arxiv.org/abs/1911.07241)]
  [[code](https://github.com/ohhhyeahhh/SiamCAR)]

* **SiamAttn:** Yuechen Yu, Yilei Xiong, Weilin Huang, Matthew R. Scott. <br />
  "Deformable Siamese Attention Networks for Visual Object Tracking." CVPR (2020).
  [[paper](https://arxiv.org/pdf/2004.06711v1.pdf)]
  
* **CSA:** Bin Yan, Dong Wang, Huchuan Lu, Xiaoyun Yang.<br />
  "Cooling-Shrinking Attack: Blinding the Tracker with Imperceptible Noises." CVPR (2020).
  [[paper](https://arxiv.org/abs/2003.09595)]
  [[code](https://github.com/MasterBin-IIAU/CSA)]

* **LTMU:** Kenan Dai, Yunhua Zhang, Dong Wang, Jianhua Li, Huchuan Lu, Xiaoyun Yang.<br />
  "High-Performance Long-Term Tracking with Meta-Updater." CVPR (2020).
  [[paper](https://arxiv.org/abs/2004.00305)]
  [[code](https://github.com/Daikenan/LTMU)]
  
* **MAST:** Zihang Lai, Erika Lu, Weidi Xie.<br />
  "MAST: A Memory-Augmented Self-supervised Tracker." CVPR (2020).
  [[paper](https://arxiv.org/abs/2002.07793)]
  [[code](https://github.com/zlai0/MAST)]
  
* **CGACD:** Fei Du, Peng Liu, Wei Zhao, Xianglong Tang.<br />
  "Correlation-Guided Attention for Corner Detection Based Visual Tracking." CVPR (2020).

### IJCAI 2020

- **TLPG-Tracker:** Siyuan Li, Zhi Zhang, Ziyu Liu, Anna Wang, Linglong Qiu, Feng Du. <br />
  "TLPG-Tracker: Joint Learning of Target Localization and Proposal Generation for Visual Tracking." IJCAI (2020).
  [[paper](https://www.ijcai.org/Proceedings/2020/99)]
  
- **E3SN:** Meng Lan, Yipeng Zhang, Qinning Xu, Lefei Zhang. <br />
  "E3SN: Efficient End-to-End Siamese Network for Video Object Segmentation." IJCAI (2020).
  [[paper](https://www.ijcai.org/Proceedings/2020/98)]
  
### AAAI 2020

- **SiamFC++:** Yinda Xu, Zeyu Wang, Zuoxin Li, Ye Yuan, Gang Yu. <br />
  "SiamFC++: Towards Robust and Accurate Visual Tracking with Target Estimation Guidelines." AAAI (2020).
  [[paper](https://arxiv.org/pdf/1911.06188v4.pdf)]
  [[code](https://github.com/MegviiDetection/video_analyst)]
  
- **DROL:** Jinghao Zhou, Peng Wang, Haoyang Sun. <br />
  "Discriminative and Robust Online Learning for Siamese Visual Tracking." AAAI (2020).
  [[paper](https://arxiv.org/abs/1909.02959)]
  [[code](https://github.com/shallowtoil/DROL)]
  
- **POST:** Ning Wang, Wengang Zhou, Guojun Qi, Houqiang Li. <br />
  "POST: POlicy-Based Switch Tracking." AAAI (2020).
  [[paper](https://ojs.aaai.org//index.php/AAAI/article/view/6899)]
  
- **SPS:** Qintao Hu, Lijun Zhou, Xiaoxiao Wang, Yao Mao, Jianlin Zhang, Qixiang Ye. <br />
  "SPSTracker: Sub-Peak Suppression of Response Map for Robust Object Tracking." AAAI (2020).
  [[paper](https://arxiv.org/pdf/1912.00597.pdf)]
  [[code](https://www.ctolib.com/https://github.com/TrackerLB/SPSTracker)]
  
- **RPOT:** Yifan Yang, Guorong Li, Yuankai Qi, Qingming Huang. <br />
  "Release the Power of Online-Training for Robust Visual Tracking." AAAI (2020).
  [[paper](https://ojs.aaai.org//index.php/AAAI/article/view/6956)]
  
- **MetaRTT:** Ilchae Jung, Kihyun You, Hyeonwoo Noh, Minsu Cho, Bohyung Han. <br />
  "Real-Time Object Tracking via Meta-Learning: Efficient Model Adaptation and One-Shot Channel Pruning." AAAI (2020).
  [[paper](https://ojs.aaai.org//index.php/AAAI/article/view/6779)]
  
- **GlobalTrack:** Lianghua Huang, Xin Zhao, Kaiqi Huang. <br />
  "GlobalTrack: A Simple and Strong Baseline for Long-term Tracking." AAAI (2020).
  [[paper](https://arxiv.org/abs/1912.08531)]
  [[code](https://github.com/huanglianghua/GlobalTrack)]

### Others 2020

* **VTT:** Tianling Bian, Yang Hua, Tao Song, Zhengui Xue, Ruhui Ma, Neil Robertson, Haibing Guan.<br />
  "VTT: Long-term Visual Tracking with Transformers." ICPR 2020. 
  [[paper](https://pure.qub.ac.uk/en/publications/vtt-long-term-visual-tracking-with-transformers)]
  [[code](https://github.com/VisualTrackingVLL)]
  
* **COMET:** Seyed Mojtaba Marvasti-Zadeh, Javad Khaghani, Hossein Ghanei-Yakhdan, Shohreh Kasaei, and Li Cheng.<br />
  "COMET: Context-aware iOu-guided network for sMall objEct Tracking." ACCV 2020. 
  [[paper](https://arxiv.org/pdf/2006.02597.pdf)]
  [[code](https://github.com/VisualTrackingVLL)]
  
* **SiamKPN:** Qiang Li, Zekui Qin, Wenbo Zhang, Wen Zheng.<br />
  "Siamese Keypoint Prediction Network for Visual Object Tracking." ArXiv 2020. 
  [[paper](https://arxiv.org/abs/2006.04078)]
  [[code](https://github.com/ZekuiQin/SiamKPN)]

* **SiamCAN:** Wenzhang Zhou, Longyin Wen, Libo Zhang, Dawei Du, Tiejian Luo, Yanjun Wu. <br />
  "SiamMan: Siamese Motion-aware Network for Visual Tracking." TIP 2020. 
  [[paper](https://arxiv.org/abs/1912.05515v2)]
  [[paper_new](https://arxiv.org/abs/1912.05515v2)]
  [[code](https://isrc.iscas.ac.cn/gitlab/research/siamcan)]
  
### ICCV 2019

* **DiMP:** Goutam Bhat, Martin Danelljan, Luc Van Gool, Radu Timofte.<br />
  "Learning Discriminative Model Prediction for Tracking." ICCV (2019 **oral**). 
  [[paper](http://openaccess.thecvf.com/content_ICCV_2019/papers/Bhat_Learning_Discriminative_Model_Prediction_for_Tracking_ICCV_2019_paper.pdf)]
  [[code](https://github.com/visionml/pytracking)]

* **GradNet:** Peixia Li, Boyu Chen, Wanli Ouyang, Dong Wang, Xiaoyun Yang, Huchuan Lu. <br />
  "GradNet: Gradient-Guided Network for Visual Object Tracking." ICCV (2019 **oral**).
  [[paper](http://openaccess.thecvf.com/content_ICCV_2019/papers/Li_GradNet_Gradient-Guided_Network_for_Visual_Object_Tracking_ICCV_2019_paper.pdf)]
  [[code](https://github.com/LPXTT/GradNet-Tensorflow)]

* **MLT:** Janghoon Choi, Junseok Kwon, Kyoung Mu Lee. <br />
  "Deep Meta Learning for Real-Time Target-Aware Visual Tracking." ICCV (2019).
  [[paper](http://openaccess.thecvf.com/content_ICCV_2019/papers/Choi_Deep_Meta_Learning_for_Real-Time_Target-Aware_Visual_Tracking_ICCV_2019_paper.pdf)]

* **SPLT:** Bin Yan, Haojie Zhao, Dong Wang, Huchuan Lu, Xiaoyun Yang <br />
  "'Skimming-Perusal' Tracking: A Framework for Real-Time and Robust Long-Term Tracking." ICCV (2019).
  [[paper](http://openaccess.thecvf.com/content_ICCV_2019/papers/Yan_Skimming-Perusal_Tracking_A_Framework_for_Real-Time_and_Robust_Long-Term_Tracking_ICCV_2019_paper.pdf)]
  [[code](https://github.com/iiau-tracker/SPLT)]

* **ARCF:** Ziyuan Huang, Changhong Fu, Yiming Li, Fuling Lin, Peng Lu. <br />
  "Learning Aberrance Repressed Correlation Filters for Real-Time UAV Tracking." ICCV (2019).
  [[paper](http://openaccess.thecvf.com/content_ICCV_2019/papers/Huang_Learning_Aberrance_Repressed_Correlation_Filters_for_Real-Time_UAV_Tracking_ICCV_2019_paper.pdf)]
  [[code](https://github.com/vision4robotics/ARCF-tracker)]

* **BGDT:** Lianghua Huang, Xin Zhao, Kaiqi Huang. <br />
  "Bridging the Gap Between Detection and Tracking: A Unified Approach." ICCV (2019).
  [[paper](http://openaccess.thecvf.com/content_ICCV_2019/papers/Huang_Bridging_the_Gap_Between_Detection_and_Tracking_A_Unified_Approach_ICCV_2019_paper.pdf)]

* **PAT:** Rey Reza Wiyatno, Anqi Xu. <br />
  "Physical Adversarial Textures That Fool Visual Object Tracking." ICCV (2019).
  [[paper](http://openaccess.thecvf.com/content_ICCV_2019/papers/Wiyatno_Physical_Adversarial_Textures_That_Fool_Visual_Object_Tracking_ICCV_2019_paper.pdf)]

* **GFS-DCF:** Tianyang Xu, Zhen-Hua Feng, Xiao-Jun Wu, Josef Kittler. <br />
  "Joint Group Feature Selection and Discriminative Filter Learning for Robust Visual Object Tracking." ICCV (2019).
  [[paper](http://openaccess.thecvf.com/content_ICCV_2019/papers/Xu_Joint_Group_Feature_Selection_and_Discriminative_Filter_Learning_for_Robust_ICCV_2019_paper.pdf)]
  [[code](https://github.com/XU-TIANYANG/GFS-DCF)]

* **CDTB:** Alan Lukežič, Ugur Kart, Jani Käpylä, Ahmed Durmush, Joni-Kristian Kämäräinen, Jiří Matas, Matej Kristan. <br />
  "CDTB: A Color and Depth Visual Object Tracking Dataset and Benchmark." ICCV (2019).
  [[paper](http://openaccess.thecvf.com/content_ICCV_2019/papers/Lukezic_CDTB_A_Color_and_Depth_Visual_Object_Tracking_Dataset_and_ICCV_2019_paper.pdf)]
  
* **fdKCF:** Linyu Zheng, Ming Tang, Yingying Chen, Jinqiao Wang, Hanqing Lu. <br />
  "Fast-deepKCF Without Boundary Effect." ICCV (2019).
  [[paper](https://openaccess.thecvf.com/content_ICCV_2019/papers/Zheng_Fast-deepKCF_Without_Boundary_Effect_ICCV_2019_paper.pdf)]

* **VOT2019:** Kristan, Matej, et al.<br />
  "The Seventh Visual Object Tracking VOT2019 Challenge Results." ICCV workshops (2019).
  [[paper](http://openaccess.thecvf.com/content_ICCVW_2019/papers/VOT/Kristan_The_Seventh_Visual_Object_Tracking_VOT2019_Challenge_Results_ICCVW_2019_paper.pdf)]

### CVPR2019

* **SiamMask:** Qiang Wang, Li Zhang, Luca Bertinetto, Weiming Hu, Philip H.S. Torr.<br />
  "Fast Online Object Tracking and Segmentation: A Unifying Approach." CVPR (2019). 
  [[paper](https://arxiv.org/pdf/1812.05050.pdf)]
  [[project](http://www.robots.ox.ac.uk/~qwang/SiamMask/)]
  [[code](https://github.com/foolwood/SiamMask)]

* **SiamRPN++:** Bo Li, Wei Wu, Qiang Wang, Fangyi Zhang, Junliang Xing, Junjie Yan.<br />
  "SiamRPN++: Evolution of Siamese Visual Tracking with Very Deep Networks." CVPR (2019 **oral**). 
  [[paper](http://openaccess.thecvf.com/content_CVPR_2019/papers/Li_SiamRPN_Evolution_of_Siamese_Visual_Tracking_With_Very_Deep_Networks_CVPR_2019_paper.pdf)]
  [[project](http://bo-li.info/SiamRPN++/)]

* **ATOM:** Martin Danelljan, Goutam Bhat, Fahad Shahbaz Khan, Michael Felsberg. <br />
  "ATOM: Accurate Tracking by Overlap Maximization." CVPR (2019 **oral**). 
  [[paper](http://openaccess.thecvf.com/content_CVPR_2019/papers/Danelljan_ATOM_Accurate_Tracking_by_Overlap_Maximization_CVPR_2019_paper.pdf)]
  [[code](https://github.com/visionml/pytracking)]

* **SiamDW:** Zhipeng Zhang, Houwen Peng.<br />
  "Deeper and Wider Siamese Networks for Real-Time Visual Tracking." CVPR (2019 **oral**). 
  [[paper](http://openaccess.thecvf.com/content_CVPR_2019/papers/Zhang_Deeper_and_Wider_Siamese_Networks_for_Real-Time_Visual_Tracking_CVPR_2019_paper.pdf)]
  [[code](https://github.com/researchmm/SiamDW)]

* **GCT:** Junyu Gao, Tianzhu Zhang, Changsheng Xu.<br />
  "Graph Convolutional Tracking." CVPR (2019 **oral**).
  [[paper](http://openaccess.thecvf.com/content_CVPR_2019/papers/Gao_Graph_Convolutional_Tracking_CVPR_2019_paper.pdf)]
  [[code](https://github.com/researchmm/SiamDW)]

* **ASRCF:** Kenan Dai, Dong Wang, Huchuan Lu, Chong Sun, Jianhua Li. <br />
  "Visual Tracking via Adaptive Spatially-Regularized Correlation Filters." CVPR (2019 **oral**).
  [[paper](http://openaccess.thecvf.com/content_CVPR_2019/papers/Dai_Visual_Tracking_via_Adaptive_Spatially-Regularized_Correlation_Filters_CVPR_2019_paper.pdf)]
  [[code](https://github.com/Daikenan/ASRCF)]

* **UDT:** Ning Wang, Yibing Song, Chao Ma, Wengang Zhou, Wei Liu, Houqiang Li.<br />
  "Unsupervised Deep Tracking." CVPR (2019). 
  [[paper](https://arxiv.org/pdf/1904.01828.pdf)]
  [[code](https://github.com/594422814/UDT)]

* **TADT:** Xin Li, Chao Ma, Baoyuan Wu, Zhenyu He, Ming-Hsuan Yang.<br />
  "Target-Aware Deep Tracking." CVPR (2019). 
  [[paper](https://arxiv.org/pdf/1904.01772.pdf)]
  [[project](https://xinli-zn.github.io/TADT-project-page/)]
  [[code](https://github.com/XinLi-zn/TADT)]

* **C-RPN:** Heng Fan, Haibin Ling.<br />
  "Siamese Cascaded Region Proposal Networks for Real-Time Visual Tracking." CVPR (2019). 
  [[paper](http://openaccess.thecvf.com/content_CVPR_2019/papers/Fan_Siamese_Cascaded_Region_Proposal_Networks_for_Real-Time_Visual_Tracking_CVPR_2019_paper.pdf)]

* **SPM:** Guangting Wang, Chong Luo, Zhiwei Xiong, Wenjun Zeng.<br />
  "SPM-Tracker: Series-Parallel Matching for Real-Time Visual Object Tracking." CVPR (2019). 
  [[paper](http://openaccess.thecvf.com/content_CVPR_2019/papers/Wang_SPM-Tracker_Series-Parallel_Matching_for_Real-Time_Visual_Object_Tracking_CVPR_2019_paper.pdf)]

* **OTR:** Ugur Kart, Alan Lukezic, Matej Kristan, Joni-Kristian Kamarainen, Jiri Matas. <br />
  "Object Tracking by Reconstruction with View-Specific Discriminative Correlation Filters." CVPR (2019). 
  [[paper](http://openaccess.thecvf.com/content_CVPR_2019/papers/Kart_Object_Tracking_by_Reconstruction_With_View-Specific_Discriminative_Correlation_Filters_CVPR_2019_paper.pdf)]
  [[code](https://github.com/ugurkart/OTR)]

* **RPCF:** Yuxuan Sun, Chong Sun, Dong Wang, Huchuan Lu, You He. <br />
  "ROI Pooled Correlation Filters for Visual Tracking." CVPR (2019).
  [[paper](http://openaccess.thecvf.com/content_CVPR_2019/papers/Sun_ROI_Pooled_Correlation_Filters_for_Visual_Tracking_CVPR_2019_paper.pdf)]

* **LaSOT:** Heng Fan, Liting Lin, Fan Yang, Peng Chu, Ge Deng, Sijia Yu, Hexin Bai, Yong Xu, Chunyuan Liao, Haibin Ling.<br />
  "LaSOT: A High-quality Benchmark for Large-scale Single Object Tracking." CVPR (2019). 
  [[paper](https://arxiv.org/pdf/1809.07845.pdf)]
  [[project](https://cis.temple.edu/lasot/)]

### AAAI2019

* **LDES:** Yang Li, Jianke Zhu, Steven C.H. Hoi, Wenjie Song, Zhefeng Wang, Hantang Liu.<br />
  "Robust Estimation of Similarity Transformation for Visual Object Tracking." AAAI (2019). 
  [[paper](https://arxiv.org/pdf/1712.05231.pdf)]
  [[code](https://github.com/ihpdep/LDES)] 
  
* **ANT:** Yuankai Qi, Shengping Zhang, Weigang Zhang, Li Su, Qingming Huang, Ming-Hsuan Yang.<br />
  "Learning Attribute-Specific Representations for Visual Tracking." AAAI (2019). 
  [[paper](https://faculty.ucmerced.edu/mhyang/papers/aaai2019_tracking.pdf)]
  
* **Re2EMA:** Jianglei Huang, Wengang Zhou.<br />
  "Re2EMA: Regularized and Reinitialized Exponential Moving Average for Target Model Update in Object Tracking." AAAI (2019). 
  [[paper](https://ojs.aaai.org//index.php/AAAI/article/view/4862)]

### NIPS2018

* **DAT:** Shi Pu, Yibing Song, Chao Ma, Honggang Zhang, Ming-Hsuan Yang.<br />
  "Deep Attentive Tracking via Reciprocative Learning." NIPS (2018). 
  [[paper](https://arxiv.org/pdf/1810.03851.pdf)] 
  [[project](https://ybsong00.github.io/nips18_tracking/index)] 
  [[code](https://github.com/shipubupt/NIPS2018)] 

### ECCV2018

* **UPDT:** Goutam Bhat, Joakim Johnander, Martin Danelljan, Fahad Shahbaz Khan, Michael Felsberg.<br />
  "Unveiling the Power of Deep Tracking." ECCV (2018). 
  [[paper](http://openaccess.thecvf.com/content_ECCV_2018/papers/Goutam_Bhat_Unveiling_the_Power_ECCV_2018_paper.pdf)]  

* **DaSiamRPN:** Zheng Zhu, Qiang Wang, Bo Li, Wu Wei, Junjie Yan, Weiming Hu.<br />
  "Distractor-aware Siamese Networks for Visual Object Tracking." ECCV (2018).
  [[paper](http://openaccess.thecvf.com/content_ECCV_2018/papers/Zheng_Zhu_Distractor-aware_Siamese_Networks_ECCV_2018_paper.pdf)]
  [[github](https://github.com/foolwood/DaSiamRPN)]
  
* **SiamMCF:** Henrique Morimitsu.<br />
  "Multiple Context Features in Siamese Networks for Visual Object Tracking." ECCV (2018).
  [[paper](https://link.springer.com/content/pdf/10.1007%2F978-3-030-11009-3_6.pdf)]
  [[github](https://github.com/hmorimitsu/siam-mcf)]

* **SACF:** Mengdan Zhang, Qiang Wang, Junliang Xing, Jin Gao, Peixi Peng, Weiming Hu, Steve Maybank.<br />
  "Visual Tracking via Spatially Aligned Correlation Filters Network." ECCV (2018).
  [[paper](http://openaccess.thecvf.com/content_ECCV_2018/papers/mengdan_zhang_Visual_Tracking_via_ECCV_2018_paper.pdf)]

* **RTINet:** Yingjie Yao, Xiaohe Wu, Lei Zhang, Shiguang Shan, Wangmeng Zuo.<br />
  "Joint Representation and Truncated Inference Learning for Correlation Filter based Tracking." ECCV (2018).
  [[paper](http://openaccess.thecvf.com/content_ECCV_2018/papers/Yingjie_Yao_Joint_Representation_and_ECCV_2018_paper.pdf)]

* **Meta-Tracker:** Eunbyung Park, Alexander C. Berg.<br />
  "Meta-Tracker: Fast and Robust Online Adaptation for Visual Object Trackers."
  [[paper](http://openaccess.thecvf.com/content_ECCV_2018/papers/Eunbyung_Park_Meta-Tracker_Fast_and_ECCV_2018_paper.pdf)]
  [[github](https://github.com/silverbottlep/meta_trackers)]

* **DSLT:** Xiankai Lu, Chao Ma*, Bingbing Ni, Xiaokang Yang, Ian Reid, Ming-Hsuan Yang.<br />
  "Deep Regression Tracking with Shrinkage Loss." ECCV (2018).
  [[paper](http://openaccess.thecvf.com/content_ECCV_2018/papers/Xiankai_Lu_Deep_Regression_Tracking_ECCV_2018_paper.pdf)]
  [[github](https://github.com/chaoma99/DSLT)]

* **DRL-IS:** Liangliang Ren, Xin Yuan, Jiwen Lu, Ming Yang, Jie Zhou.<br />
  "Deep Reinforcement Learning with Iterative Shift for Visual Tracking." ECCV (2018).
  [[paper](http://openaccess.thecvf.com/content_ECCV_2018/papers/Liangliang_Ren_Deep_Reinforcement_Learning_ECCV_2018_paper.pdf)]

* **RT-MDNet:** Ilchae Jung, Jeany Son, Mooyeol Baek, Bohyung Han.<br />
  "Real-Time MDNet." ECCV (2018).
  [[paper](http://openaccess.thecvf.com/content_ECCV_2018/papers/Ilchae_Jung_Real-Time_MDNet_ECCV_2018_paper.pdf)]

* **ACT:** Boyu Chen, Dong Wang, Peixia Li, Huchuan Lu.<br />
  "Real-time 'Actor-Critic' Tracking." ECCV (2018).
  [[paper](http://openaccess.thecvf.com/content_ECCV_2018/papers/Boyu_Chen_Real-time_Actor-Critic_Tracking_ECCV_2018_paper.pdf)]
  [[github](https://github.com/bychen515/ACT)]

* **StructSiam:** Yunhua Zhang, Lijun Wang, Dong Wang, Mengyang Feng, Huchuan Lu, Jinqing Qi.<br />
  "Structured Siamese Network for Real-Time Visual Tracking." ECCV (2018).
  [[paper](http://openaccess.thecvf.com/content_ECCV_2018/papers/Yunhua_Zhang_Structured_Siamese_Network_ECCV_2018_paper.pdf)]

* **MemTrack:** Tianyu Yang, Antoni B. Chan.<br />
  "Learning Dynamic Memory Networks for Object Tracking." ECCV (2018).
  [[paper](http://openaccess.thecvf.com/content_ECCV_2018/papers/Tianyu_Yang_Learning_Dynamic_Memory_ECCV_2018_paper.pdf)]

* **SiamFC-tri:** Xingping Dong, Jianbing Shen.<br />
  "Triplet Loss in Siamese Network for Object Tracking." ECCV (2018).
  [[paper](http://openaccess.thecvf.com/content_ECCV_2018/papers/Xingping_Dong_Triplet_Loss_with_ECCV_2018_paper.pdf)]
  [[github](https://github.com/shenjianbing/TripletTracking)]

* **OxUvA long-term dataset+benchmark:** Jack Valmadre, Luca Bertinetto, João F. Henriques, Ran Tao, Andrea Vedaldi, Arnold Smeulders, Philip Torr, Efstratios Gavves.<br />
  "Long-term Tracking in the Wild: a Benchmark." ECCV (2018).
  [[paper](http://openaccess.thecvf.com/content_ECCV_2018/papers/Efstratios_Gavves_Long-term_Tracking_in_ECCV_2018_paper.pdf)]
  [[project](https://oxuva.github.io/long-term-tracking-benchmark/)]

* **TrackingNet:** Matthias Müller, Adel Bibi, Silvio Giancola, Salman Al-Subaihi, Bernard Ghanem.<br />
  "TrackingNet: A Large-Scale Dataset and Benchmark for Object Tracking in the Wild." ECCV (2018).
  [[paper](http://openaccess.thecvf.com/content_ECCV_2018/papers/Matthias_Muller_TrackingNet_A_Large-Scale_ECCV_2018_paper.pdf)] 
  [[project](http://tracking-net.org/)]


### CVPR2018

* **VITAL:** Yibing Song, Chao Ma, Xiaohe Wu, Lijun Gong, Linchao Bao, Wangmeng Zuo, Chunhua Shen, Rynson Lau, and Ming-Hsuan Yang.
  "VITAL: VIsual Tracking via Adversarial Learning." CVPR (2018 **Spotlight**). 
  [[project](https://ybsong00.github.io/cvpr18_tracking/index)]
  [[paper](http://openaccess.thecvf.com/content_cvpr_2018/papers/Song_VITAL_VIsual_Tracking_CVPR_2018_paper.pdf)]
  [[github](https://github.com/ybsong00/Vital_release)]

* **LSART:** Chong Sun, Dong Wang, Huchuan Lu, Ming-Hsuan Yang.
  "Learning Spatial-Aware Regressions for Visual Tracking." CVPR (2018 **Spotlight**). 
  [[paper](http://openaccess.thecvf.com/content_cvpr_2018/papers/Sun_Learning_Spatial-Aware_Regressions_CVPR_2018_paper.pdf)]

* **SiamRPN:** Bo Li, Wei Wu, Zheng Zhu, Junjie Yan.
  "High Performance Visual Tracking with Siamese Region Proposal Network." CVPR (2018 **Spotlight**). 
  [[paper](http://openaccess.thecvf.com/content_cvpr_2018/papers/Li_High_Performance_Visual_CVPR_2018_paper.pdf)]

* **TRACA:** Jongwon Choi, Hyung Jin Chang, Tobias Fischer, Sangdoo Yun, Kyuewang Lee, Jiyeoup Jeong, Yiannis Demiris, Jin Young Choi.
  "Context-aware Deep Feature Compression for High-speed Visual Tracking." CVPR (2018). 
  [[project](https://sites.google.com/site/jwchoivision/)]
  [[paper](http://openaccess.thecvf.com/content_cvpr_2018/papers/Choi_Context-Aware_Deep_Feature_CVPR_2018_paper.pdf)]

* **RASNet:** Qiang Wang, Zhu Teng, Junliang Xing, Jin Gao, Weiming Hu, Stephen Maybank.
  "Learning Attentions: Residual Attentional Siamese Network for High Performance Online Visual Tracking." CVPR 2018. 
  [[paper](http://openaccess.thecvf.com/content_cvpr_2018/papers/Wang_Learning_Attentions_Residual_CVPR_2018_paper.pdf)]

* **SA-Siam:** Anfeng He, Chong Luo, Xinmei Tian, Wenjun Zeng.
  "A Twofold Siamese Network for Real-Time Object Tracking." CVPR (2018). 
  [[paper](http://openaccess.thecvf.com/content_cvpr_2018/papers/He_A_Twofold_Siamese_CVPR_2018_paper.pdf)]

* **STRCF:** Feng Li, Cheng Tian, Wangmeng Zuo, Lei Zhang, Ming-Hsuan Yang.
  "Learning Spatial-Temporal Regularized Correlation Filters for Visual Tracking." CVPR (2018). 
  [[paper](http://openaccess.thecvf.com/content_cvpr_2018/papers/Li_Learning_Spatial-Temporal_Regularized_CVPR_2018_paper.pdf)]
  [[github](https://github.com/lifeng9472/STRCF)]

* **FlowTrack:** Zheng Zhu, Wei Wu, Wei Zou, Junjie Yan.
  "End-to-end Flow Correlation Tracking with Spatial-temporal Attention." CVPR (2018). 
  [[paper](http://openaccess.thecvf.com/content_cvpr_2018/papers/Zhu_End-to-End_Flow_Correlation_CVPR_2018_paper.pdf)]

* **DEDT:** Kourosh Meshgi, Shigeyuki Oba, Shin Ishii.
  "Efficient Diverse Ensemble for Discriminative Co-Tracking." CVPR (2018). 
  [[paper](http://openaccess.thecvf.com/content_cvpr_2018/papers/Meshgi_Efficient_Diverse_Ensemble_CVPR_2018_paper.pdf)]

* **SINT++:** Xiao Wang, Chenglong Li, Bin Luo, Jin Tang.
  "SINT++: Robust Visual Tracking via Adversarial Positive Instance Generation." CVPR (2018).
  [[paper](http://openaccess.thecvf.com/content_cvpr_2018/papers/Wang_SINT_Robust_Visual_CVPR_2018_paper.pdf)]

* **DRT:** Chong Sun, Dong Wang, Huchuan Lu, Ming-Hsuan Yang.
  "Correlation Tracking via Joint Discrimination and Reliability Learning." CVPR (2018). 
  [[paper](http://openaccess.thecvf.com/content_cvpr_2018/papers/Sun_Correlation_Tracking_via_CVPR_2018_paper.pdf)]

* **MCCT:** Ning Wang, Wengang Zhou, Qi Tian, Richang Hong, Meng Wang, Houqiang Li.
  "Multi-Cue Correlation Filters for Robust Visual Tracking." CVPR (2018). 
  [[paper](http://openaccess.thecvf.com/content_cvpr_2018/papers/Wang_Multi-Cue_Correlation_Filters_CVPR_2018_paper.pdf)]
  [[github](https://github.com/594422814/MCCT)]

* **MKCF:** Ming Tang, Bin Yu, Fan Zhang, Jinqiao Wang.
  "High-speed Tracking with Multi-kernel Correlation Filters." CVPR (2018).
  [[paper](http://openaccess.thecvf.com/content_cvpr_2018/papers/Tang_High-Speed_Tracking_With_CVPR_2018_paper.pdf)]

* **HP:** Xingping Dong, Jianbing Shen, Wenguan Wang, Yu, Liu, Ling Shao, and Fatih Porikli.
  "Hyperparameter Optimization for Tracking with Continuous Deep Q-Learning." CVPR (2018).
  [[paper](http://openaccess.thecvf.com/content_cvpr_2018/papers/Dong_Hyperparameter_Optimization_for_CVPR_2018_paper.pdf)]

### NIPS2017

* **HART:** Adam R. Kosiorek, Alex Bewley, Ingmar Posner. 
  "Hierarchical Attentive Recurrent Tracking." NIPS (2017). 
  [[paper](https://papers.nips.cc/paper/6898-hierarchical-attentive-recurrent-tracking.pdf)]
  [[github](https://github.com/akosiorek/hart)]


### ICCV2017

* **CREST:** Yibing Song, Chao Ma, Lijun Gong, Jiawei Zhang, Rynson Lau, Ming-Hsuan Yang. 
  "CREST: Convolutional Residual Learning for Visual Tracking." ICCV (2017 **Spotlight**). 
  [[paper](http://openaccess.thecvf.com/content_ICCV_2017/papers/Song_CREST_Convolutional_Residual_ICCV_2017_paper.pdf)]
  [[project](http://www.cs.cityu.edu.hk/~yibisong/iccv17/index.html)]
  [[github](https://github.com/ybsong00/CREST-Release)]

* **EAST:** Chen Huang, Simon Lucey, Deva Ramanan.
  "Learning Policies for Adaptive Tracking with Deep Feature Cascades." ICCV (2017 **Spotlight**). 
  [[paper](http://openaccess.thecvf.com/content_ICCV_2017/papers/Huang_Learning_Policies_for_ICCV_2017_paper.pdf)]
  [[supp](http://openaccess.thecvf.com/content_ICCV_2017/supplemental/Huang_Learning_Policies_for_ICCV_2017_supplemental.zip)]

* **PTAV:** Heng Fan and Haibin Ling. 
  "Parallel Tracking and Verifying: A Framework for Real-Time and High Accuracy Visual Tracking." ICCV (2017). 
  [[paper](http://openaccess.thecvf.com/content_ICCV_2017/papers/Fan_Parallel_Tracking_and_ICCV_2017_paper.pdf)]
  [[supp](http://openaccess.thecvf.com/content_ICCV_2017/supplemental/Fan_Parallel_Tracking_and_ICCV_2017_supplemental.pdf)]
  [[project](http://www.dabi.temple.edu/~hbling/code/PTAV/ptav.htm)]
  [[code](http://www.dabi.temple.edu/~hbling/code/PTAV/serial_ptav_v1.zip)]

* **BACF:** Hamed Kiani Galoogahi, Ashton Fagg, Simon Lucey. 
  "Learning Background-Aware Correlation Filters for Visual Tracking." ICCV (2017). 
  [[paper](http://openaccess.thecvf.com/content_ICCV_2017/papers/Galoogahi_Learning_Background-Aware_Correlation_ICCV_2017_paper.pdf)]
  [[supp](http://openaccess.thecvf.com/content_ICCV_2017/supplemental/Galoogahi_Learning_Background-Aware_Correlation_ICCV_2017_supplemental.pdf)]
  [[code](http://www.hamedkiani.com/uploads/5/1/8/8/51882963/bacf_toupload.zip)]
  [[project](http://www.hamedkiani.com/bacf.html)]

* **TSN:** Zhu Teng, Junliang Xing, Qiang Wang, Congyan Lang, Songhe Feng and Yi Jin.
  "Robust Object Tracking based on Temporal and Spatial Deep Networks." ICCV (2017).
  [[paper](http://openaccess.thecvf.com/content_ICCV_2017/papers/Teng_Robust_Object_Tracking_ICCV_2017_paper.pdf)]

* **p-tracker:** James Supančič, III; Deva Ramanan.
  "Tracking as Online Decision-Making: Learning a Policy From Streaming Videos With Reinforcement Learning." ICCV (2017).
  [[paper](http://openaccess.thecvf.com/content_ICCV_2017/papers/Supancic_Tracking_as_Online_ICCV_2017_paper.pdf)]
  [[supp](http://openaccess.thecvf.com/content_ICCV_2017/supplemental/Supancic_Tracking_as_Online_ICCV_2017_supplemental.pdf)]

* **DSiam:** Qing Guo; Wei Feng; Ce Zhou; Rui Huang; Liang Wan; Song Wang.
  "Learning Dynamic Siamese Network for Visual Object Tracking." ICCV (2017).
  [[paper](http://openaccess.thecvf.com/content_ICCV_2017/papers/Guo_Learning_Dynamic_Siamese_ICCV_2017_paper.pdf)]
  [[github](https://github.com/tsingqguo/DSiam)]

* **SP-KCF:** Xin Sun; Ngai-Man Cheung; Hongxun Yao; Yiluan Guo.
  "Non-Rigid Object Tracking via Deformable Patches Using Shape-Preserved KCF and Level Sets." ICCV (2017).
  [[paper](http://openaccess.thecvf.com/content_ICCV_2017/papers/Sun_Non-Rigid_Object_Tracking_ICCV_2017_paper.pdf)]

* **UCT:** Zheng Zhu, Guan Huang, Wei Zou, Dalong Du, Chang Huang.
  "UCT: Learning Unified Convolutional Networks for Real-Time Visual Tracking." ICCV workshop (2017).
  [[paper](http://openaccess.thecvf.com/content_ICCV_2017_workshops/papers/w28/Zhu_UCT_Learning_Unified_ICCV_2017_paper.pdf)]

* Tobias Bottger, Patrick Follmann.
  "The Benefits of Evaluating Tracker Performance Using Pixel-Wise Segmentations." ICCV workshop (2017).
  [[paper](http://openaccess.thecvf.com/content_ICCV_2017_workshops/papers/w28/Bottger_The_Benefits_of_ICCV_2017_paper.pdf)]

* **CFWCR:** Zhiqun He, Yingruo Fan, Junfei Zhuang, Yuan Dong, HongLiang Bai.
  "Correlation Filters With Weighted Convolution Responses." ICCV workshop (2017).
  [[paper](http://openaccess.thecvf.com/content_ICCV_2017_workshops/papers/w28/He_Correlation_Filters_With_ICCV_2017_paper.pdf)]
  [[github](https://github.com/he010103/CFWCR)]

* **IBCCF:** Feng Li, Yingjie Yao, Peihua Li, David Zhang, Wangmeng Zuo, Ming-Hsuan Yang.
  "Integrating Boundary and Center Correlation Filters for Visual Tracking With Aspect Ratio Variation." ICCV workshop (2017).
  [[paper](http://openaccess.thecvf.com/content_ICCV_2017_workshops/papers/w28/Li_Integrating_Boundary_and_ICCV_2017_paper.pdf)]
  [[github](https://github.com/lifeng9472/IBCCF)]

* **RFL:** Tianyu Yang, Antoni B. Chan.
  "Recurrent Filter Learning for Visual Tracking." ICCV workshop (2017).
  [[paper](http://openaccess.thecvf.com/content_ICCV_2017_workshops/papers/w28/Yang_Recurrent_Filter_Learning_ICCV_2017_paper.pdf)]


### CVPR2017

* **ECO:** Martin Danelljan, Goutam Bhat, Fahad Shahbaz Khan, Michael Felsberg. 
  "ECO: Efficient Convolution Operators for Tracking." CVPR (2017). 
  [[paper](http://openaccess.thecvf.com/content_cvpr_2017/papers/Danelljan_ECO_Efficient_Convolution_CVPR_2017_paper.pdf)]
  [[supp](http://openaccess.thecvf.com/content_cvpr_2017/supplemental/Danelljan_ECO_Efficient_Convolution_2017_CVPR_supplemental.pdf)]
  [[project](http://www.cvl.isy.liu.se/research/objrec/visualtracking/ecotrack/index.html)]
  [[github](https://github.com/martin-danelljan/ECO)]

* **CFNet:** Jack Valmadre, Luca Bertinetto, João F. Henriques, Andrea Vedaldi, Philip H. S. Torr.
  "End-to-end representation learning for Correlation Filter based tracking." CVPR (2017). 
  [[paper](http://openaccess.thecvf.com/content_cvpr_2017/papers/Valmadre_End-To-End_Representation_Learning_CVPR_2017_paper.pdf)]
  [[supp](http://openaccess.thecvf.com/content_cvpr_2017/supplemental/Valmadre_End-To-End_Representation_Learning_2017_CVPR_supplemental.pdf)]
  [[project](http://www.robots.ox.ac.uk/~luca/cfnet.html)]
  [[github](https://github.com/bertinetto/cfnet)]

* **CACF:** Matthias Mueller, Neil Smith, Bernard Ghanem. 
  "Context-Aware Correlation Filter Tracking." CVPR (2017 **oral**). 
  [[paper](http://openaccess.thecvf.com/content_cvpr_2017/papers/Mueller_Context-Aware_Correlation_Filter_CVPR_2017_paper.pdf)]
  [[supp](http://openaccess.thecvf.com/content_cvpr_2017/supplemental/Mueller_Context-Aware_Correlation_Filter_2017_CVPR_supplemental.zip)]
  [[project](https://ivul.kaust.edu.sa/Pages/pub-ca-cf-tracking.aspx)]
  [[code](https://github.com/thias15/Context-Aware-CF-Tracking)]

* **RaF:** Le Zhang, Jagannadan Varadarajan, Ponnuthurai Nagaratnam Suganthan, Narendra Ahuja and Pierre Moulin
  "Robust Visual Tracking Using Oblique Random Forests." CVPR (2017). 
  [[paper](http://openaccess.thecvf.com/content_cvpr_2017/papers/Zhang_Robust_Visual_Tracking_CVPR_2017_paper.pdf)]
  [[supp](http://openaccess.thecvf.com/content_cvpr_2017/supplemental/Zhang_Robust_Visual_Tracking_2017_CVPR_supplemental.pdf)]
  [[project](https://sites.google.com/site/zhangleuestc/incremental-oblique-random-forest)]
  [[code](https://github.com/ZhangLeUestc/Incremental-Oblique-Random-Forest)]

* **MCPF:** Tianzhu Zhang, Changsheng Xu, Ming-Hsuan Yang. 
  "Multi-Task Correlation Particle Filter for Robust Object Tracking." CVPR (2017). 
  [[paper](http://openaccess.thecvf.com/content_cvpr_2017/papers/Zhang_Multi-Task_Correlation_Particle_CVPR_2017_paper.pdf)]
  [[project](http://nlpr-web.ia.ac.cn/mmc/homepage/tzzhang/mcpf.html)]
  [[code](http://nlpr-web.ia.ac.cn/mmc/homepage/tzzhang/mcpf.html)]

* **ACFN:** Jongwon Choi, Hyung Jin Chang, Sangdoo Yun, Tobias Fischer, Yiannis Demiris, and Jin Young Choi.
  "Attentional Correlation Filter Network for Adaptive Visual Tracking." CVPR (2017).
  [[paper](http://openaccess.thecvf.com/content_cvpr_2017/papers/Choi_Attentional_Correlation_Filter_CVPR_2017_paper.pdf)]
  [[supp](http://openaccess.thecvf.com/content_cvpr_2017/supplemental/Choi_Attentional_Correlation_Filter_2017_CVPR_supplemental.pdf)]
  [[project](https://sites.google.com/site/jwchoivision/home/acfn-1)]
  [[test code](https://drive.google.com/file/d/0B0ZkG8zaRQoLQUswbW9qSWFaU0U/view?usp=drive_web)]
  [[training code](https://drive.google.com/file/d/0B0ZkG8zaRQoLZVVranBnbHlydnM/view?usp=drive_web)]

* **LMCF:** Mengmeng Wang, Yong Liu, Zeyi Huang. 
  "Large Margin Object Tracking with Circulant Feature Maps." CVPR (2017). 
  [[paper](http://openaccess.thecvf.com/content_cvpr_2017/papers/Wang_Large_Margin_Object_CVPR_2017_paper.pdf)]
  [[zhihu](https://zhuanlan.zhihu.com/p/25761718)]

* **ADNet:** Sangdoo Yun, Jongwon Choi, Youngjoon Yoo, Kimin Yun, Jin Young Choi.
  "Action-Decision Networks for Visual Tracking with Deep Reinforcement Learning." CVPR (2017 **Spotlight**). 
  [[paper](http://openaccess.thecvf.com/content_cvpr_2017/papers/Yun_Action-Decision_Networks_for_CVPR_2017_paper.pdf)]
  [[supp](http://openaccess.thecvf.com/content_cvpr_2017/supplemental/Yun_Action-Decision_Networks_for_2017_CVPR_supplemental.pdf)]
  [[project](https://sites.google.com/view/cvpr2017-adnet)]

* **CSR-DCF:** Alan Lukežič, Tomáš Vojíř, Luka Čehovin, Jiří Matas, Matej Kristan. 
  "Discriminative Correlation Filter with Channel and Spatial Reliability." CVPR (2017). 
  [[paper](http://openaccess.thecvf.com/content_cvpr_2017/papers/Lukezic_Discriminative_Correlation_Filter_CVPR_2017_paper.pdf)]
  [[supp](http://openaccess.thecvf.com/content_cvpr_2017/supplemental/Lukezic_Discriminative_Correlation_Filter_2017_CVPR_supplemental.pdf)]
  [[code](https://github.com/alanlukezic/csr-dcf)]

* **BranchOut:** Bohyung Han, Jack Sim, Hartwig Adam.
  "BranchOut: Regularization for Online Ensemble Tracking with Convolutional Neural Networks." CVPR (2017). 
  [[paper](http://openaccess.thecvf.com/content_cvpr_2017/papers/Han_BranchOut_Regularization_for_CVPR_2017_paper.pdf)]

* **AMCT:** Donghun Yeo, Jeany Son, Bohyung Han, Joonhee Han.
  "Superpixel-based Tracking-by-Segmentation using Markov Chains." CVPR (2017).
  [[paper](http://openaccess.thecvf.com/content_cvpr_2017/papers/Yeo_Superpixel-Based_Tracking-By-Segmentation_Using_CVPR_2017_paper.pdf)]

* **SANet:** Heng Fan, Haibin Ling. 
  "SANet: Structure-Aware Network for Visual Tracking." CVPRW (2017). 
  [[paper](https://arxiv.org/pdf/1611.06878.pdf)]
  [[project](http://www.dabi.temple.edu/~hbling/code/SANet/SANet.html)]
  [[code](http://www.dabi.temple.edu/~hbling/code/SANet/sanet_code.zip)]

### ECCV2016

* **SiameseFC:** Luca Bertinetto, Jack Valmadre, João F. Henriques, Andrea Vedaldi, Philip H.S. Torr. 
  "Fully-Convolutional Siamese Networks for Object Tracking." ECCV workshop (2016). 
  [[paper](http://120.52.73.78/arxiv.org/pdf/1606.09549v2.pdf)]
  [[project](http://www.robots.ox.ac.uk/~luca/siamese-fc.html)]
  [[github](https://github.com/bertinetto/siamese-fc)]

* **GOTURN:** David Held, Sebastian Thrun, Silvio Savarese. 
  "Learning to Track at 100 FPS with Deep Regression Networks." ECCV (2016). 
  [[paper](http://davheld.github.io/GOTURN/GOTURN.pdf)]
  [[project](http://davheld.github.io/GOTURN/GOTURN.html)]
  [[github](https://github.com/davheld/GOTURN)]

* **C-COT:** Martin Danelljan, Andreas Robinson, Fahad Khan, Michael Felsberg. 
  "Beyond Correlation Filters: Learning Continuous Convolution Operators for Visual Tracking." ECCV (2016). 
  [[paper](http://www.cvl.isy.liu.se/research/objrec/visualtracking/conttrack/C-COT_ECCV16.pdf)]
  [[project](http://www.cvl.isy.liu.se/research/objrec/visualtracking/conttrack/index.html)]
  [[github](https://github.com/martin-danelljan/Continuous-ConvOp)]

* **CF+AT:** Adel Bibi, Matthias Mueller, and Bernard Ghanem. 
  "Target Response Adaptation for Correlation Filter Tracking." ECCV (2016). 
  [[paper](http://www.adelbibi.com/papers/ECCV2016/Target_Adap.pdf)]
  [[project](https://ivul.kaust.edu.sa/Pages/pub-target-response-adaptation.aspx)]
  [[github](https://github.com/adelbibi/Target-Response-Adaptation-for-Correlation-Filter-Tracking)]

* Yao Sui, Ziming Zhang,  Guanghui Wang, Yafei Tang, Li Zhang. 
  "Real-Time Visual Tracking: Promoting the Robustness of Correlation Filter Learning." ECCV (2016). 
  [[paper](http://120.52.73.78/arxiv.org/pdf/1608.08173.pdf)]

* Yao Sui, Guanghui Wang, Yafei Tang, Li Zhang. 
  "Tracking Completion." ECCV (2016). 
  [[paper](http://120.52.73.78/arxiv.org/pdf/1608.08171v1.pdf)]

### CVPR2016

* **MDNet:** Nam, Hyeonseob, and Bohyung Han. 
  "Learning Multi-Domain Convolutional Neural Networks for Visual Tracking." CVPR (2016).
  [[paper](http://arxiv.org/pdf/1510.07945v2.pdf)]
  [[VOT_presentation](http://votchallenge.net/vot2015/download/presentation_Hyeonseob.pdf)]
  [[project](http://cvlab.postech.ac.kr/research/mdnet/)]
  [[github](https://github.com/HyeonseobNam/MDNet)]

* **SINT:** Ran Tao, Efstratios Gavves, Arnold W.M. Smeulders. 
  "Siamese Instance Search for Tracking." CVPR (2016).
  [[paper](https://staff.science.uva.nl/r.tao/pub/TaoCVPR2016.pdf)]
  [[project](https://staff.fnwi.uva.nl/r.tao/projects/SINT/SINT_proj.html)]

* **SCT:** Jongwon Choi, Hyung Jin Chang, Jiyeoup Jeong, Yiannis Demiris, and Jin Young Choi.
  "Visual Tracking Using Attention-Modulated Disintegration and Integration." CVPR (2016).
  [[paper](http://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Choi_Visual_Tracking_Using_CVPR_2016_paper.pdf)]
  [[project](https://sites.google.com/site/jwchoivision/home/sct)]

* **STCT:** Lijun Wang, Wanli Ouyang, Xiaogang Wang, and Huchuan Lu.
  "STCT: Sequentially Training Convolutional Networks for Visual Tracking." CVPR (2016).
  [[paper](http://www.ee.cuhk.edu.hk/~wlouyang/Papers/WangLJ_CVPR16.pdf)]
  [[github](https://github.com/scott89/STCT)]

* **SRDCFdecon:** Martin Danelljan, Gustav Häger, Fahad Khan, Michael Felsberg. 
  "Adaptive Decontamination of the Training Set: A Unified Formulation for Discriminative Visual Tracking." CVPR (2016).
  [[paper](https://www.cvl.isy.liu.se/research/objrec/visualtracking/decontrack/AdaptiveDecon_CVPR16.pdf)]
  [[project](https://www.cvl.isy.liu.se/research/objrec/visualtracking/decontrack/index.html)]

* **HDT:** Yuankai Qi, Shengping Zhang, Lei Qin, Hongxun Yao, Qingming Huang, Jongwoo Lim, Ming-Hsuan Yang. 
  "Hedged Deep Tracking." CVPR (2016). 
  [[paper](http://faculty.ucmerced.edu/mhyang/papers/cvpr16_hedge_tracking.pdf)]
  [[project](https://sites.google.com/site/yuankiqi/hdt/)]

* **Staple:** Luca Bertinetto, Jack Valmadre, Stuart Golodetz, Ondrej Miksik, Philip H.S. Torr. 
  "Staple: Complementary Learners for Real-Time Tracking." CVPR (2016). 
  [[paper](http://120.52.73.75/arxiv.org/pdf/1512.01355v2.pdf)]
  [[project](http://www.robots.ox.ac.uk/~luca/staple.html)]
  [[github](https://github.com/bertinetto/staple)]

* **EBT:** Gao Zhu, Fatih Porikli, and Hongdong Li.
  "Beyond Local Search: Tracking Objects Everywhere with Instance-Specific Proposals." CVPR (2016). 
  [[paper](http://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Zhu_Beyond_Local_Search_CVPR_2016_paper.pdf)]
  [[exe](http://www.votchallenge.net/vot2016/download/02_EBT.zip)]

* **DLSSVM:** Jifeng Ning, Jimei Yang, Shaojie Jiang, Lei Zhang and Ming-Hsuan Yang. 
  "Object Tracking via Dual Linear Structured SVM and Explicit Feature Map." CVPR (2016). 
  [[paper](http://www4.comp.polyu.edu.hk/~cslzhang/paper/cvpr16/DLSSVM.pdf)]
  [[code](http://www4.comp.polyu.edu.hk/~cslzhang/code/DLSSVM_CVPR.zip)]
  [[project](http://www4.comp.polyu.edu.hk/~cslzhang/DLSSVM/DLSSVM.htm)]

### NIPS2016
* **Learnet:** Luca Bertinetto, João F. Henriques, Jack Valmadre, Philip H. S. Torr, Andrea Vedaldi. 
  "Learning feed-forward one-shot learners." NIPS (2016). 
  [[paper](https://arxiv.org/pdf/1606.05233v1.pdf)]

### ICCV2015

* **FCNT:** Lijun Wang, Wanli Ouyang, Xiaogang Wang, and Huchuan Lu. 
  "Visual Tracking with Fully Convolutional Networks." ICCV (2015). 
  [[paper](http://202.118.75.4/lu/Paper/ICCV2015/iccv15_lijun.pdf)]
  [[project](http://scott89.github.io/FCNT/)]
  [[github](https://github.com/scott89/FCNT)]

* **SRDCF:** Martin Danelljan, Gustav Häger, Fahad Khan, Michael Felsberg. 
  "Learning Spatially Regularized Correlation Filters for Visual Tracking." ICCV (2015). 
  [[paper](https://www.cvl.isy.liu.se/research/objrec/visualtracking/regvistrack/SRDCF_ICCV15.pdf)]
  [[project](https://www.cvl.isy.liu.se/research/objrec/visualtracking/regvistrack/)]

* **CF2:** Chao Ma, Jia-Bin Huang, Xiaokang Yang and Ming-Hsuan Yang.
  "Hierarchical Convolutional Features for Visual Tracking." ICCV (2015)
  [[paper](http://faculty.ucmerced.edu/mhyang/papers/iccv15_tracking.pdf)]
  [[project](https://sites.google.com/site/jbhuang0604/publications/cf2)]
  [[github](https://github.com/jbhuang0604/CF2)]

* Naiyan Wang, Jianping Shi, Dit-Yan Yeung and Jiaya Jia.
  "Understanding and Diagnosing Visual Tracking Systems." ICCV (2015). 
  [[paper](http://winsty.net/papers/diagnose.pdf)]
  [[project](http://winsty.net/tracker_diagnose.html)]
  [[code](http://winsty.net/diagnose/diagnose_code.zip)]\

* **DeepSRDCF:** Martin Danelljan, Gustav Häger, Fahad Khan, Michael Felsberg. 
  "Convolutional Features for Correlation Filter Based Visual Tracking." ICCV workshop (2015). 
  [[paper](https://www.cvl.isy.liu.se/research/objrec/visualtracking/regvistrack/ConvDCF_ICCV15_VOTworkshop.pdf)]
  [[project](https://www.cvl.isy.liu.se/research/objrec/visualtracking/regvistrack/)]

* **RAJSSC:** Mengdan Zhang, Junliang Xing, Jin Gao, Xinchu Shi, Qiang Wang, Weiming Hu. 
  "Joint Scale-Spatial Correlation Tracking with Adaptive Rotation Estimation." ICCV workshop (2015). 
  [[paper](http://www.cv-foundation.org//openaccess/content_iccv_2015_workshops/w14/papers/Zhang_Joint_Scale-Spatial_Correlation_ICCV_2015_paper.pdf)]
  [[poster](http://www.votchallenge.net/vot2015/download/poster_Mengdan_Zhang.pdf)]

### CVPR2015

* **MUSTer:** Zhibin Hong, Zhe Chen, Chaohui Wang, Xue Mei, Danil Prokhorov, Dacheng Tao. 
  "MUlti-Store Tracker (MUSTer): A Cognitive Psychology Inspired Approach to Object Tracking." CVPR (2015). 
  [[paper](http://openaccess.thecvf.com/content_cvpr_2015/papers/Hong_MUlti-Store_Tracker_MUSTer_2015_CVPR_paper.pdf)]
  [[project](https://sites.google.com/site/multistoretrackermuster/)]

* **LCT:** Chao Ma, Xiaokang Yang, Chongyang Zhang, Ming-Hsuan Yang.
  "Long-term Correlation Tracking." CVPR (2015).
  [[paper](http://openaccess.thecvf.com/content_cvpr_2015/papers/Ma_Long-Term_Correlation_Tracking_2015_CVPR_paper.pdf)]
  [[project](https://sites.google.com/site/chaoma99/cvpr15_tracking)]
  [[github](https://github.com/chaoma99/lct-tracker)]

* **DAT:** Horst Possegger, Thomas Mauthner, and Horst Bischof. 
  "In Defense of Color-based Model-free Tracking." CVPR (2015). 
  [[paper](https://lrs.icg.tugraz.at/pubs/possegger_cvpr15.pdf)]
  [[project](https://www.tugraz.at/institute/icg/research/team-bischof/lrs/downloads/dat)]
  [[code](https://lrs.icg.tugraz.at/downloads/dat-v1.0.zip)]

* **RPT:** Yang Li, Jianke Zhu and Steven C.H. Hoi. 
  "Reliable Patch Trackers: Robust Visual Tracking by Exploiting Reliable Patches." CVPR (2015). 
  [[paper](https://github.com/ihpdep/ihpdep.github.io/raw/master/papers/cvpr15_rpt.pdf)]
  [[github](https://github.com/ihpdep/rpt)]

### ICML2015

* **CNN-SVM:** Seunghoon Hong, Tackgeun You, Suha Kwak and Bohyung Han.
  "Online Tracking by Learning Discriminative Saliency Map with Convolutional Neural Network ." ICML (2015)
  [[paper](http://120.52.73.80/arxiv.org/pdf/1502.06796.pdf)]
  [[project](http://cvlab.postech.ac.kr/research/CNN_SVM/)]

### BMVC2014

* **DSST:** Martin Danelljan, Gustav Häger, Fahad Shahbaz Khan and Michael Felsberg. 
  "Accurate Scale Estimation for Robust Visual Tracking." BMVC (2014).
  [[paper](http://www.cvl.isy.liu.se/research/objrec/visualtracking/scalvistrack/ScaleTracking_BMVC14.pdf)]
  [[PAMI](http://www.cvl.isy.liu.se/en/research/objrec/visualtracking/scalvistrack/DSST_TPAMI.pdf)]
  [[project](http://www.cvl.isy.liu.se/en/research/objrec/visualtracking/scalvistrack/index.html)]

### ECCV2014

* **MEEM:** Jianming Zhang, Shugao Ma, and Stan Sclaroff.
  "MEEM: Robust Tracking via Multiple Experts using Entropy Minimization." ECCV (2014).
  [[paper](http://cs-people.bu.edu/jmzhang/MEEM/MEEM-eccv-preprint.pdf)]
  [[project](http://cs-people.bu.edu/jmzhang/MEEM/MEEM.html)]

* **TGPR:** Jin Gao, Haibin Ling, Weiming Hu, Junliang Xing.
  "Transfer Learning Based Visual Tracking with Gaussian Process Regression." ECCV (2014).
  [[paper](http://www.dabi.temple.edu/~hbling/publication/tgpr-eccv14.pdf)]
  [[project](http://www.dabi.temple.edu/~hbling/code/TGPR.htm)]

* **STC:** Kaihua Zhang, Lei Zhang, Ming-Hsuan Yang, David Zhang.
  "Fast Tracking via Spatio-Temporal Context Learning." ECCV (2014).
  [[paper](http://arxiv.org/pdf/1311.1939v1.pdf)]
  [[project](http://www4.comp.polyu.edu.hk/~cslzhang/STC/STC.htm)]

* **SAMF:** Yang Li, Jianke Zhu.
  "A Scale Adaptive Kernel Correlation Filter Tracker with Feature Integration." ECCV workshop (2014).
  [[paper](http://link.springer.com/content/pdf/10.1007%2F978-3-319-16181-5_18.pdf)]
  [[github](https://github.com/ihpdep/samf)]

### NIPS2013

* **DLT:** Naiyan Wang and Dit-Yan Yeung. 
  "Learning A Deep Compact Image Representation for Visual Tracking." NIPS (2013). 
  [[paper](http://winsty.net/papers/dlt.pdf)]
  [[project](http://winsty.net/dlt.html)]
  [[code](http://winsty.net/dlt/DLTcode.zip)]
 
 ### PAMI & IJCV & TIP

* **MCPF:** Tianzhu Zhang, Changsheng Xu, Ming-Hsuan Yang.
    " Learning Multi-task Correlation Particle Filters for Visual Tracking." TPAMI (2017).
      [[paper]]
      [[project](http://nlpr-web.ia.ac.cn/mmc/homepage/tzzhang/lmcpf.html)]
      [[code](http://nlpr-web.ia.ac.cn/mmc/homepage/tzzhang/Project_Tianzhu/zhang_mcpf/Source_Code/Source_Code.zip)] 

* **RSST:** Tianzhu Zhang, Changsheng Xu, Ming-Hsuan Yang.
  " Robust Structural Sparse Tracking." TPAMI (2017).
  [[paper]]
  [[project](http://nlpr-web.ia.ac.cn/mmc/homepage/tzzhang/rsst.html)]
  [[code](http://nlpr-web.ia.ac.cn/mmc/homepage/tzzhang/Project_Tianzhu/zhang_RSST/RSSTDeep/RSSTDeep_Code.zip)] 

* **fDSST:** Martin Danelljan, Gustav Häger, Fahad Khan, Michael Felsberg.
  "Discriminative Scale Space Tracking." TPAMI (2017).
  [[paper](http://www.cvl.isy.liu.se/research/objrec/visualtracking/scalvistrack/DSST_TPAMI.pdf)]
  [[project](http://www.cvl.isy.liu.se/research/objrec/visualtracking/scalvistrack/index.html)]
  [[code](http://www.cvl.isy.liu.se/research/objrec/visualtracking/scalvistrack/fDSST_code.zip)] 

* **KCF:** João F. Henriques, Rui Caseiro, Pedro Martins, Jorge Batista. 
  "High-Speed Tracking with Kernelized Correlation Filters." TPAMI (2015).
  [[paper](http://www.robots.ox.ac.uk/~joao/publications/henriques_tpami2015.pdf)]
  [[project](http://www.robots.ox.ac.uk/~joao/circulant/)]

* **CLRST:** Tianzhu Zhang, Si Liu, Narendra Ahuja, Ming-Hsuan Yang, Bernard Ghanem.  
  "Robust Visual Tracking Via Consistent Low-Rank Sparse Learning." IJCV (2015). 
  [[paper](http://nlpr-web.ia.ac.cn/mmc/homepage/tzzhang/tianzhu%20zhang_files/Journal%20Articles/IJCV15_zhang_Low-Rank%20Sparse%20Learning.pdf)]
  [[project](http://nlpr-web.ia.ac.cn/mmc/homepage/tzzhang/Project_Tianzhu/zhang_IJCV14/Robust%20Visual%20Tracking%20Via%20Consistent%20Low-Rank%20Sparse.html)]
  [[code](http://nlpr-web.ia.ac.cn/mmc/homepage/tzzhang/Project_Tianzhu/zhang_IJCV14/material/LRT_Code.zip)]

* **DNT:** Zhizhen Chi, Hongyang Li, Huchuan Lu, Ming-Hsuan Yang. 
  "Dual Deep Network for Visual Tracking." TIP (2017). 
  [[paper](https://arxiv.org/pdf/1612.06053v1.pdf)]

* **DRT:** Junyu Gao, Tianzhu Zhang, Xiaoshan Yang, Changsheng Xu. 
  "Deep Relative Tracking." TIP (2017). 
  [[paper](http://ieeexplore.ieee.org/abstract/document/7828108/)]

* **BIT:** Bolun Cai, Xiangmin Xu, Xiaofen Xing, Kui Jia, Jie Miao, Dacheng Tao.
  "BIT: Biologically Inspired Tracker." TIP (2016). 
  [[paper](http://caibolun.github.io/papers/BIT_TIP.pdf)]
  [[project](http://caibolun.github.io/BIT/index.html)]
  [[github](https://github.com/caibolun/BIT)]

* **CNT:** Kaihua Zhang, Qingshan Liu, Yi Wu, Minghsuan Yang. 
  "Robust Visual Tracking via Convolutional Networks Without Training." TIP (2016). 
  [[paper](http://kaihuazhang.net/CNT.pdf)]
  [[code](http://kaihuazhang.net/CNT_matlab.rar)]
  
  ## ArXiv

* **MLT:** Janghoon Choi, Junseok Kwon, Kyoung Mu Lee.
  "Deep Meta Learning for Real-Time Visual Tracking based on Target-Specific Feature Space." arXiv (2017). 
  [[paper](https://arxiv.org/pdf/1712.09153v1.pdf)]

* **PAWSS:** Xiaofei Du, Alessio Dore, Danail Stoyanov. 
  "Patch-based adaptive weighting with segmentation and scale (PAWSS) for visual tracking." arXiv (2017). 
  [[paper](https://arxiv.org/pdf/1708.01179v1.pdf)]

* **SFT:** Zhen Cui, You yi Cai, Wen ming Zheng, Jian Yang. 
  "Spectral Filter Tracking." arXiv (2017). 
  [[paper](https://arxiv.org/pdf/1707.05553v1.pdf)]

* **Re3:** Daniel Gordon, Ali Farhadi, Dieter Fox. 
  "Re3 : Real-Time Recurrent Regression Networks for Object Tracking." arXiv (2017). 
  [[paper](https://arxiv.org/pdf/1705.06368.pdf)]

* **DCFNet:** Qiang Wang, Jin Gao, Junliang Xing, Mengdan Zhang, Weiming Hu. 
  "DCFNet: Discriminant Correlation Filters Network for Visual Tracking." arXiv (2017). 
  [[paper](https://arxiv.org/pdf/1704.04057.pdf)]
  [[code](https://github.com/foolwood/DCFNet#dcfnet-discriminant-correlation-filters-network-for-visual-tracking)]

* **TCNN:** Hyeonseob Nam, Mooyeol Baek, Bohyung Han. 
  "Modeling and Propagating CNNs in a Tree Structure for Visual Tracking." arXiv (2016). 
  [[paper](http://arxiv.org/pdf/1608.07242v1.pdf)]
  [[code](http://www.votchallenge.net/vot2016/download/44_TCNN.zip)]

* **RDT:** Janghoon Choi, Junseok Kwon, Kyoung Mu Lee. 
  "Visual Tracking by Reinforced Decision Making." arXiv (2017). 
  [[paper](https://arxiv.org/pdf/1702.06291.pdf)]

* **MSDAT:** Xinyu Wang, Hanxi Li, Yi Li, Fumin Shen, Fatih Porikli .
  "Robust and Real-time Deep Tracking Via Multi-Scale Domain Adaptation." arXiv (2017). 
  [[paper](https://arxiv.org/pdf/1701.00561.pdf)]

* **RLT:** Da Zhang, Hamid Maei, Xin Wang, Yuan-Fang Wang.
  "Deep Reinforcement Learning for Visual Object Tracking in Videos." arXiv (2017). 
  [[paper](https://arxiv.org/pdf/1701.08936v1.pdf)]

* **SCF:** Wangmeng Zuo, Xiaohe Wu, Liang Lin, Lei Zhang, Ming-Hsuan Yang. 
  "Learning Support Correlation Filters for Visual Tracking." arXiv (2016).
  [[paper](https://arxiv.org/pdf/1601.06032.pdf)]
  [[project](http://faculty.ucmerced.edu/mhyang/project/scf/)]

* **CRT:** Kai Chen, Wenbing Tao. 
  "Convolutional Regression for Visual Tracking." arXiv (2016). 
  [[paper](https://arxiv.org/pdf/1611.04215.pdf)]

* **BMR:** Kaihua Zhang, Qingshan Liu, and Ming-Hsuan Yang. 
  "Visual Tracking via Boolean Map Representations." arXiv (2016). 
  [[paper](https://arxiv.org/pdf/1610.09652v1.pdf)]

* **YCNN:** Kai Chen, Wenbing Tao. 
  "Once for All: a Two-flow Convolutional Neural Network for Visual Tracking." arXiv (2016). 
  [[paper](https://arxiv.org/pdf/1604.07507v1.pdf)]

* **ROLO:** Guanghan Ning, Zhi Zhang, Chen Huang, Zhihai He, Xiaobo Ren, Haohong Wang. 
  "Spatially Supervised Recurrent Convolutional Neural Networks for Visual Object Tracking." arXiv (2016). 
  [[paper](http://arxiv.org/pdf/1607.05781v1.pdf)]
  [[project](http://guanghan.info/projects/ROLO/)]
  [[github](https://github.com/Guanghan/ROLO/)]

* **SO-DLT:** Naiyan Wang, Siyi Li, Abhinav Gupta, Dit-Yan Yeung. 
  "Transferring Rich Feature Hierarchies for Robust Visual Tracking." arXiv (2015). 
  [[paper](https://arxiv.org/pdf/1501.04587v2.pdf)]
  [[code](http://www.votchallenge.net/vot2016/download/08_SO-DLT.zip)]

* **DMSRDCF:** Susanna Gladh, Martin Danelljan, Fahad Shahbaz Khan, Michael Felsberg. 
  "Deep Motion Features for Visual Tracking." ICPR **Best Paper** (2016). 
  [[paper](https://arxiv.org/pdf/1612.06615v1.pdf)]

## Benchmark

* **LaSOT:** Heng Fan, Liting Lin, Fan Yang, Peng Chu, Ge Deng, Sijia Yu, Hexin Bai, Yong Xu, Chunyuan Liao, Haibin Ling.
  "Deep Meta Learning for Real-Time Visual Tracking based on Target-Specific Feature Space." arXiv (2018). 
  [[paper](https://arxiv.org/pdf/1809.07845.pdf)]
  [[project](https://cis.temple.edu/lasot/)]

* **OxUvA long-term dataset+benchmark:** Jack Valmadre, Luca Bertinetto, João F. Henriques, Ran Tao, Andrea Vedaldi, Arnold Smeulders, Philip Torr, Efstratios Gavves.<br />
  "Long-term Tracking in the Wild: a Benchmark." ECCV (2018).
  [[paper](https://arxiv.org/pdf/1803.09502.pdf)]
  [[project](https://oxuva.github.io/long-term-tracking-benchmark/)]

* **TrackingNet:** Matthias Müller, Adel Bibi, Silvio Giancola, Salman Al-Subaihi, Bernard Ghanem.<br />
  "TrackingNet: A Large-Scale Dataset and Benchmark for Object Tracking in the Wild." ECCV (2018).
  [[project](https://silviogiancola.github.io/publication/2018-03-trackingnet/details/)]
  [[paper](https://arxiv.org/pdf/1803.10794.pdf)] 

* **UAVDT:** Dawei Du, Yuankai Qi, Hongyang Yu, Yifang Yang, Kaiwen Duan, GuoRong Li, Weigang Zhang,  Weihai; Qingming Huang, Qi Tian.<br />
  "The Unmanned Aerial Vehicle Benchmark: Object Detection and Tracking." ECCV (2018).
  [[paper](https://arxiv.org/pdf/1804.00518.pdf)]

* **Dataset-AMP:** Luka Čehovin Zajc; Alan Lukežič; Aleš Leonardis; Matej Kristan.
  "Beyond Standard Benchmarks: Parameterizing Performance Evaluation in Visual Object Tracking." ICCV (2017).
  [[paper](http://openaccess.thecvf.com/content_ICCV_2017/papers/Zajc_Beyond_Standard_Benchmarks_ICCV_2017_paper.pdf)]

* **Dataset-Nfs:** Hamed Kiani Galoogahi, Ashton Fagg, Chen Huang, Deva Ramanan and Simon Lucey.
  "Need for Speed: A Benchmark for Higher Frame Rate Object Tracking." ICCV (2017)
  [[paper](http://openaccess.thecvf.com/content_ICCV_2017/papers/Galoogahi_Need_for_Speed_ICCV_2017_paper.pdf)]
  [[supp](http://openaccess.thecvf.com/content_ICCV_2017/supplemental/Galoogahi_Need_for_Speed_ICCV_2017_supplemental.pdf)]
  [[project](http://ci2cv.net/nfs/index.html)]

* **Dataset-DTB70:** Siyi Li, Dit-Yan Yeung.
  "Visual Object Tracking for Unmanned Aerial Vehicles: A Benchmark and New Motion Models." AAAI (2017)
  [[paper](http://aaai.org/ocs/index.php/AAAI/AAAI17/paper/view/14338/14292)]
  [[project](https://github.com/flyers/drone-tracking)]
  [[dataset](https://www.dropbox.com/s/s1fj99s2six4lrs/DTB70.tar.gz?dl=0)]

* **Dataset-UAV123:** Matthias Mueller, Neil Smith and Bernard Ghanem.
  "A Benchmark and Simulator for UAV Tracking." ECCV (2016)
  [[paper](https://ivul.kaust.edu.sa/Documents/Publications/2016/A%20Benchmark%20and%20Simulator%20for%20UAV%20Tracking.pdf)]
  [[project](https://ivul.kaust.edu.sa/Pages/pub-benchmark-simulator-uav.aspx)]
  [[dataset](https://ivul.kaust.edu.sa/Pages/Dataset-UAV123.aspx)]

* **Dataset-TColor-128:** Pengpeng Liang, Erik Blasch, Haibin Ling.
  "Encoding color information for visual tracking: Algorithms and benchmark." TIP (2015)
  [[paper](http://www.dabi.temple.edu/~hbling/publication/TColor-128.pdf)]
  [[project](http://www.dabi.temple.edu/~hbling/data/TColor-128/TColor-128.html)]
  [[dataset](http://www.dabi.temple.edu/~hbling/data/TColor-128/Temple-color-128.zip)]

* **Dataset-NUS-PRO:** Annan Li, Min Lin, Yi Wu, Ming-Hsuan Yang, and Shuicheng Yan.
  "NUS-PRO: A New Visual Tracking Challenge." PAMI (2015)
  [[paper](http://faculty.ucmerced.edu/mhyang/papers/pami15_nus_pro.pdf)]
  [[project](https://sites.google.com/site/li00annan/nus-pro)]
  [[Data_360](https://d9fca6.lc.yunpan.cn/lk/cqKIc6DU3t2eJ)(code:bf28)]
  [[Data_baidu]](https://pan.baidu.com/s/1pJHvbSn#list/path=%2F)]
  [[View_360](https://6aa275.lc.yunpan.cn/lk/cqK479PfzDrPX)(code:515a)]
  [[View_baidu]](https://pan.baidu.com/s/1hqKXcuK)]

* **Dataset-PTB:** Shuran Song and Jianxiong Xiao.
  "Tracking Revisited using RGBD Camera: Unified Benchmark and Baselines." ICCV (2013)
  [[paper](http://vision.princeton.edu/projects/2013/tracking/paper.pdf)]
  [[project](http://tracking.cs.princeton.edu/)]
  [[5 validation](http://tracking.cs.princeton.edu/ValidationSet.zip)]
  [[95 evaluation](http://tracking.cs.princeton.edu/EvaluationSet.tgz)]

* **Dataset-ALOV300+:** Arnold W. M. Smeulders, Dung M. Chu, Rita Cucchiara, Simone Calderara, Afshin Dehghan, Mubarak Shah.
  "Visual Tracking: An Experimental Survey." PAMI (2014)
  [[paper](http://crcv.ucf.edu/papers/Tracking_Survey.pdf)]
  [[project](http://imagelab.ing.unimore.it/dsm/)]
  [Mirror Link:ALOV300++ Dataset](http://crcv.ucf.edu/people/phd_students/afshin/ALOV300/Frames.zip)
  [Mirror Link:ALOV300++ Groundtruth](http://crcv.ucf.edu/people/phd_students/afshin/ALOV300/GT.zip)

* **OTB2013:** Wu, Yi, Jongwoo Lim, and Minghsuan Yang. 
  "Online Object Tracking: A Benchmark." CVPR (2013).
  [[paper](http://faculty.ucmerced.edu/mhyang/papers/cvpr13_benchmark.pdf)]

* **OTB2015:** Wu, Yi, Jongwoo Lim, and Minghsuan Yang. 
  "Object Tracking Benchmark." TPAMI (2015).
  [[paper](http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7001050&tag=1)]
  [[project](http://cvlab.hanyang.ac.kr/tracker_benchmark/index.html)]

* **Dataset-VOT:**
  **[[project](http://www.votchallenge.net/)]**

**[[VOT13_paper_ICCV](http://www.votchallenge.net/vot2013/Download/vot_2013_paper.pdf)]The Visual Object Tracking VOT2013 challenge results**

**[[VOT14_paper_ECCV](http://www.votchallenge.net/vot2014/download/vot_2014_paper.pdf)]The Visual Object Tracking VOT2014 challenge results**

**[[VOT15_paper_ICCV](http://www.votchallenge.net/vot2015/download/vot_2015_paper.pdf)]The Visual Object Tracking VOT2015 challenge results**

**[[VOT16_paper_ECCV](http://www.votchallenge.net/vot2016/download/vot_2016_paper.pdf)]The Visual Object Tracking VOT2016 challenge results**

**[[VOT17_paper_ICCV](http://openaccess.thecvf.com/content_ICCV_2017_workshops/papers/w28/Kristan_The_Visual_Object_ICCV_2017_paper.pdf)]The Visual Object Tracking VOT2017 challenge results**


## Distinguished Researchers & Teams
Distinguished visual tracking researchers who have published +3 papers which have a major impact on the field of visual tracking and are still active in the field of visual tracking.(Names listed in no particular order.)

* [Ming-Hsuan Yang](http://faculty.ucmerced.edu/mhyang/)
* [Haibin Ling](http://www.dabi.temple.edu/~hbling/)
* [Huchuan Lu](http://ice.dlut.edu.cn/lu/)
* [Hongdong Li](http://users.cecs.anu.edu.au/~hongdong/)
* [Lei Zhang](http://www4.comp.polyu.edu.hk/~cslzhang/)
* [Matej Kristan](http://www.vicos.si/People/Matejk)
* [João F. Henriques](http://www.robots.ox.ac.uk/~joao/)
* [Martin Danelljan](http://users.isy.liu.se/cvl/marda26/)
* [Kaihua Zhang](http://kaihuazhang.net/)
* [Hamed Kiani](http://www.hamedkiani.com/)
* [Luca Bertinetto](http://www.robots.ox.ac.uk/~luca/index.html)
* [Tianzhu Zhang](http://nlpr-web.ia.ac.cn/mmc/homepage/tzzhang/index.html)
* [Chao Ma](https://www.chaoma.info/)
* [Yibing Song](https://ybsong00.github.io/)
* [Dong Wang](http://www.escience.cn/people/wangdongdut/index.html)
* [**Torr Vision Group**](http://www.robots.ox.ac.uk/~tvg/people.php)
* [**Computer Vision Laboratory, POSTECH**](http://cvlab.postech.ac.kr/lab/index.php)
